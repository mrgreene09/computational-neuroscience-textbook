[
["index.html", "Computational Neuroscience 1 Preface 1.1 This book is free (as in pizza) 1.2 This book is free (as in speech) 1.3 This book can be revised and disseminated more rapidly than traditional textbooks 1.4 This book creates a public record of learning that exists after the semester ends 1.5 Authors: Version 0.0 1.6 Authors: Version 1.0", " Computational Neuroscience Students of NS/PY 357 Bates College 2020-10-21 1 Preface What you are about to read is an open textbook written for (and by) students of Computational Neuroscience at Bates College. This is version 1.0 of a living document that will be revised, reused, and appended over the course of many generations of this course. As the instructor of this course, I want to briefly outline my motivations for undertaking this project in hopes that this idea may spread. 1.1 This book is free (as in pizza) It is broadly accepted that college affordability is a key challenge for the U.S. in the 21st century. One of the drivers of increased college cost is the increased cost of course textbooks. Over the past 40 years, textbook prices have risen over 1200% over the last 40 years – much higher than the rate of inflation, and higher even than housing or healthcare! By creating a free textbook, we are broadening the participation of students in computational neuroscience. While this was true when we began this project in 2019, it is even more true as we face a global pandemic and recession in 2020. I am very happy to be opening up knowledge on this topic as the world seems more closed. As the class reflected on their work, a number of additional novel reasons for this project emerged: reducing the environmental impact of creating and shipping paper textbooks, and the health implications of sharing physical textbooks during a pandemic. 1.2 This book is free (as in speech) As important as cost-free textbooks is, equally important are the freedoms that openness provides. We are opening this resource for reuse, revision, and redistribution. We welcome others to remix into other works. It is my belief that the availability of high-quality resources allows for creativity and innovation to spring up in others. My teaching and scholarship has benefited greatly from openly available sources, and I feel that my success as an academic is to pay this forward. 1.3 This book can be revised and disseminated more rapidly than traditional textbooks Part of the impetus of this book came from a frustration in finding a traditional textbook that was appropriate for my undergraduate, 300-level course in computational neuroscience. Many of the books, though excellent, assumed a graduate-level sophistication in mathematics. Nearly all were missing some of the most modern topics. Computational neuroscience is a rapidly-evolving field, so an open textbook allows for more rapid editing, addition, and dissemination than is afforded by a traditional publishing model. 1.4 This book creates a public record of learning that exists after the semester ends Part of the educational journey is making the leap between being a consumer of knowledge to being a generator of knowledge. It is oft-said but nonetheless true statement that one truly learns by teaching. This assignment places students in the role of teacher, making the content come alive by explaining it in their own words. All too often, the writing that we do in college is in the form of the “disposable assignment” - one that students will spend a few hours working on, that I will spend a few hours reading and grading, and then is thrown away. Writing an open textbook is more of a renewable assignment - one that will have value in the world long after the semester is over. We hope that you enjoy this book. Please feel free to reach out to me if you have any questions or comments about our work: mgreene2@bates.edu. 1.5 Authors: Version 0.0 Juliet Bockhorst (2022) Abraham Brownell (2020) Paloma Noriega Burrill (2021) Catherine Crossin (2020) Leo Crossman (2020) Logan Douglas (2020) Nick Antonellis (2021) Robin Kass (2020) Sasha Cadariu (2021) Wuyue Zhou (2021) 1.6 Authors: Version 1.0 Ciaran Bardong (2022) Camden Bibro (2022) Natalie Brewer (2021) Yueh Chuah (2022) Alexis Fifield (2021) Neeshi Hullavarad (2022) Jahmari Josiah (2021) Johnny Loftus (2022) Adam Mann (2021) Amina Mohamed (2022) Alexia Perugini (2022) Shanzeh Rauf (2021) Peter Riley (2022) Sobie Sobolewski (2022) Riley Strathmann (2022) Dessy Yang (2022) This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["Ch1.html", "2 Introduction to Python 2.1 Vocabulary 2.2 Introduction 2.3 Summary 2.4 Example Python Problems 2.5 Conceptual Exercises for Learning Python 2.6 Coding Exercises for Learning Python", " 2 Introduction to Python 2.1 Vocabulary 2.2 Introduction 2.3 Summary 2.4 Example Python Problems Example 1: Programming is essentially simplifying steps of a task to an alien that doesn’t understand how humans think. You need to be specific, detailed, and consistent in the format. The computer has a few basic commands it can do, so you need to be creative about how you’ll lay out the steps. With this in mind how would you explain to a computer how to get pizza from Commons? Solution (outline): You would first need to give the computer directions to Commons Scan its ID to enter Commons from the west facing door Proceed to the first scanning station, scan its ID, and wait in line Proceed to the pizza station which is on the left side of the building Look at the types of pizza there are and decide which one it wants Ask the Commons employee for the pizza it wants Take its box and follow the signs to exit Scan out and exit through the east facing doors Example 2: The type() function tells you what type of data a certain variable is. Predict what Python will return for the following commands: a.) type (“hello world”) b.) type(747) c.) type(3.14) Solution: a.) string b.) integer c.) float Example 3: Python is a simple programming language and doesn’t naturally come with all of the functions you might need. However, there is no reason to worry. Because Python is so ubiquitous, you can find downloadable packages of code to perform things you might otherwise sink hours into programming. One of these packages is numpy which performs many mathematical calculations that Python doesn’t come equipped with. Here are some examples of numpy functions: # exponential numpy.exp(x) # square root numpy.sqrt(x) # natural log numpy.log(x) In order to use these functions you must first import the package into your notebook which can simply be done with the import function: import numpy Example 4: Write code to do the following and print them: a.) \\(e^8\\) b.) \\(\\sqrt{55+31}\\) c.) \\(\\ln(664/41)\\) Solution: # part a print(numpy.exp(8)) # part b print(numpy.sqrt(55+31)) # part c print(numpy.log(664/41)) Example 5: “If” statements are rather straightforward. You tell Python what to do if a particular circumstance is true. For example: # pick a random integer between 1 and 10 x = np.random.randint(10) # print &quot;okie dokie&quot; for if x is small, but print &quot;nokie dokie&quot; # for larger values if 4&gt;x: print(&quot;okie dokie&quot;) else: print(&quot;nokie dokie&quot;) In this example we are using the numpy.random.randint function to generate a random number between 0-9 and storing it in the variable x. This is because the numpy.random.randint function begins counting at 0 and is not inclusive of the last digit. The if statement then tells Python that if the randomly generated number is less than four print okie dokie and if not print nokie dokie. You can run this code multiple times and see the changes. Example 6: Now try it yourself. Imagine you’re playing the lottery and your numbers are 3, 22, 55, and 31 and numbers are selected between 0 and 150, you win if any of your numbers are selected. Write an “if” statement that returns “I’m loaded!!!” if your numbers are not selected, print “better luck next time”. Hint: the “==” symbols are used to show equivalency. “Or” is a function that can be used in conjunction with “if” statements. Solution: # print a random integer between 1 and 56 x = numpy.random.randint(57) # check to see if x is a winning number if x==3 or x==22 or x==55 or x==31: print(&quot;I&#39;m loaded!&quot;) else: print(&quot;Better luck next time!&quot;) # check what number was chosen print(x) Example 7: Imagine you are cleaning up at the end of your birthday party. You are tired and hungry from a long day of having fun. You are wondering how many slices of pizza are left in each of the 5 pizza boxes, and you decide to write an algorithm that will look through each pizza box and count the number of remaining slices. Follow the comments below to understand what each line of this code does: # We are importing the package numpy which has built in functions # that will make coding easier and more efficient. import numpy # We are defining the total number of pizza boxes that we need # to examine. totalBoxes = 5 # Start counting the number of pizza slices. Since we haven&#39;t # started counting, we will start at zero. count = 0 # Here we are initializing the for loop. We are telling Python # to look at each box in the range of totalBoxes. for box in range(totalBoxes): # We’ve indented here because we are working inside the for loop. # The numpy.random.randint() function is selecting a random # number between 0 and 16 (we use 17 because the numpy random # function is not inclusive of the last digit). This will # represent the number of slices left in this box. slices = numpy.random.randint(0, high=17) # We are telling Python that if there is at least one slice in # the box, we should increase the count and print the number of # slices found. if slices &gt; 0: count += slices print(&#39;I have found {} slices!&#39;.format(count)) # &quot;Else&quot; tells Python what to do if there is no pizza in this box. else: #Print is indented inside the else statement because you want to # print (&quot;Nooooooo!!!&quot;) if the else statement needs to be used. print(&quot;Nooooooo!!!&quot;) 2.5 Conceptual Exercises for Learning Python How does Python read code? Compare and contrast the function of brackets and parentheses. How is a tuple different than a list, and given their respective scenarios what characters should be used? Why is indentation important when using writing code in Python, and how can it affect your cell outcome? Describe the four most common data types (int, float, bool, str) that variables can be assigned to and describe each one. 2.6 Coding Exercises for Learning Python Define two variables, one called varOne that represents the value 20 and one calledvarTwo that represents the value 5: Creating a new variable called addVar, write a code that will add varOne andvarTwo. Creating a new variable called divVar, write a code that will divide varOne andvarTwo. Finally, multiply your two new values (from parts a + b), and assign this to the variable multVar. Hint: use basic addition, divison, and multiplication commands rather than making your own function. Using the variable name L1: Create a list of five different food items and print the list. Write a line of Python code that will print only the 3rd and 5th food in your list from part a. Using variable name L2: c. Create a second list with three sport names and print the list. d. Write a line of Python code that will sort your list from part c alphabetically. Create a vector from 5 to 15 (non-inclusive) in increments of 2. Then write a line of code that will print the square of each value in the vector. Create a matrix of zeros with 3 rows and 6 columns. Then, create a 2x4 matrix where the first row lists ice cream flavors and the second row lists soda flavors. Write a for loop that will start at the lowest temperature you experienced this week and end at the highest temperature you experienced (in one degree increments). Inside your loop, use an if…else statement that prints whether each temperature is even or odd. "],
["Ch2.html", "3 What is Computational Neuroscience? 3.1 Vocabulary 3.2 Introduction 3.3 What is computational neuroscience? 3.4 Levels of organization 3.5 Applications of computational neuroscience 3.6 The future of computational neuroscience 3.7 Summary 3.8 Exercises:", " 3 What is Computational Neuroscience? 3.1 Vocabulary Algorithm Bottom-up processing Computational neuroscience Computational theory Emergent phenomena Hardware and implementation Hebbian learning Reconstruction Reductionism Reductionism Representation Top-down processing Turing machine 3.2 Introduction Look at this picture of a desk on the page in front of you. As you look at it, your brain is somehow able to turn the raw sense data coming from your eyes into a judgment about the identity of the object in the image. If we want to build a machine that can demonstrate a similar capacity to judge — then we need to be able to model and understand the mechanisms that are at work when we see the desk. We are now left with at least two questions: (1) How might we create a computer program that performs the same cognitive tasks as us humans? And (2) What can such as program tell us about the mechanisms at work in our own human brains? While these questions may not be exhaustive of the concerns of computational neuroscience, they should at least give you a taste of some of the issues the discipline grapples with on a regular basis. For more information please explore. 3.3 What is computational neuroscience? Computational neuroscience is an interdisciplinary field that applies the principles of mathematics, philosophy, and computer science to study the inner workings of the brain. Computer models are critical to computational neuroscience, because they allow experiments to be conducted in a highly controlled and replicable fashion. In this context, a “model” is a simplified and simulated version of a system that tries to guess how the actual (simulated) system would behave in the real world. For example, suppose a computational neuroscientist wants to understand how the human brain begins to make sense of sounds. A computer model could be constructed for this purpose, because many disparate aspects of the hearing parts of the brain have been measured. Such measurements would make constructing a useful computer model possible, because they would constrain the design model. In other words, our researcher could design a model where the simulated features match the measurements of the corresponding real features of the brain. This model could be useful, because our researcher has access to all the features of the computer model—including those that could not be easily and ethically measured in the actual human brain. This utility would be borne out in plausible inferences about currently unmeasured properties and behaviors of the brain. While it is true that the inferences we’ve just discussed can not be made with complete certainty, they can be instrumental in guiding future research as new technology (and sources of funding) become available. Even if a given model ends up not holding up to future data, the model could still prove useful for developing artificial intelligences. With the potential of computer models of the brain in mind, it may be tempting to think you could build a model that truly “understands” in the same way that a person does. The question of whether or not such a model is possible is a matter of much debate, so suffice it to say we will only briefly survey the issues here. On the side arguing that a computer model could never truly understand something (e.g. the Chinese language) the way a human does is the philosopher John Searle. Searle makes use of his famous “Chinese Room Argument” to suggest that merely following a set of rules to produce a desired result from a given input is not enough to count as true understanding. For example, Searle would argue that using a big book of rules for writing Chinese answers that respond to Chinese questions is not the same thing as having a natural conversation in Chinese.1 This may seem intuitively true, but many of Searle’s opponents2 argue that Searle’s alleged argument is only intuitively true. That is to say that Searle is merely provoking intuitions rather than supplying premises or facts that lead to his desired conclusion. The motivations for this debate could be explained in terms of the level of organization at which Searle and his opponents appear to be thinking. While Searle published his paper on the “Chinese Room Argument” in 1980, the conversation of whether computers would be able to fully understand humans had been ongoing for many decades prior. In 1936, Alan Turing, created the theory of the Turing test to find when there was an equivalence between artificial intelligence and humans. Turing found the limitations of computation by understanding the limitations of humanity, and thus he created the Turing Machine. This machine paved way for the turing test, that tested whether a human could determine whether they were interacting with another machine or another human. Hence, the question of how to tell when artificial intelligence will be comparable to human intelligence is an ongoing problem today. Figure 3.1: Example of Conway’s Game of Life 3.4 Levels of organization In 1982, David Marr, introduced a new approach to analysis. He believed that there were three levels in the model of the brain. The first level is the computational theory, , which is a description of the information going into the system, and the corresponding output desired from the system. An example of this is addition. The input is two numbers, and the desired output is the sum of those numbers. The second level consists of the representational scheme and the algorithm. The representational scheme is the description of the functional elements that are used in the computation, while the algorithm is the set of operations that are performed with or by those elements in order to carry out the transformation specified by the computational theory. One example is a cookbook recipe; this will define a step by step process (an algorithm) for how to produce a product given a set of clearly defined ingredients (a representational scheme). The third level is hardware implementation, which refers to the physical machinery that realizes the algorithm. The goal of computational neuroscience is to be able to replicate the functions of the brain, such as the one you just performed, in a non-organic setting. One of the ways to do this is through computer programming software, such as the application Python. Consider the following basic code: Here is an example of an addition problem coded in Python. We can see the input, the algorithm which is transforming the input, and then the correct output of 4. Given the properties of coding software such as Python, which takes input, and runs it through a set algorithm. Is this similar to the way we humans do it? If so, how? If not, why not? 3.5 Applications of computational neuroscience As we delve deeper into Computational Neuroscience, we will find that the field has a variety of potential applications when it comes to understanding how cognition happens. Computational Neuroscience, perhaps most importantly, allows us to create models of our cognitive processes, such that they are able to capture the basis of complex phenomena in a simple way. The brain is an extremely complex organ, and while we may not always understand all of its architecture and functionality, by using methods of Computational Neuroscience we are able to abstract certain notions to the extent that they become comprehensible. In doing so, we develop the ability to understand interactions between neurons in the brain and begin seeing the nature of certain causal relationships. Furthermore, we can begin to predict how complex systems in the brain will behave when presented with particular stimuli. This may all seem rather abstract, so let’s think of an example we often take for granted: Vision. How is it that we are capable of recognizing a variety of highly specific things and distinguishing them from one another? What constitutes recognition and the neural processes behind it? How do we decide what deserves recognition and what doesn’t? Why is it so difficult to replicate these seemingly innate processes in a robot? All these questions can be addressed using Computational Neuroscience. We must, however, keep one thing in mind. When creating models, the correct level of simplicity is difficult if not impossible to discern. So, it is important to engage in criticism and scrutiny when developing the simplest and most efficient model one can think of. Figure 3.2: One example of emergent phenomena are the flight patterns of geese. One goose alone flies as it wishes but a collection of geese come together to form a v-shaped pattern that affects the overall movement of the geese. You may be saying to yourself, “Ok, well all this is great in theory, but where do we begin?”. We start by trying to establish Emergent Phenomena. Emergent Phenomena allow us to reframe composite systems such that we are able to understand their underlying mechanisms in simpler terms. To clarify, an Emergent Phenomenon can highlight both the mechanics and the nature of a particular system. For instance, a normal car cannot function properly unless it has four wheels. However, the car also derives part of its “car-ness” from the fact that it has four wheels. There are two primary schools of thought in this domain: Reductionism and Reconstructionism. Reductionism is the idea that in order to understand a given complex system, we must be able to reduce it to its simplest form, while Reconstructionism claims that we go in the opposite direction and reconstruct the system such that we are able to capture its complexity. After all, when we create models of the brain, it is not sufficient to explain their architecture. We must also show how the architecture gives rise to certain relationships and interactions. To do this, we can design our models using one of the following approaches: Top-down processing or Bottom-up processing. Top-down processing makes us design our models with a certain purpose, or goal in mind. Bottom-up processing leads us to establish a base of information or data before creating the model, and then creating the model and its purpose off of what we have collected. 3.6 The future of computational neuroscience Figure 3.3: This image can be approached in two different ways. For bottom-up processing, we can see the letters first and then figure out the words. For top-down processing, we can see the words and decide what each letter is. Given all this information, what is the future of Computational Neuroscience? Interest in the field is increasing steadily and everyday the range of its possible applications grows. In 2013, the Obama administration began the BRAIN initiative, a program designed to facilitate the development of innovative technologies that allow for a well-rounded and versatile understanding of brain function. In 2005, a Swiss team of scientists began another initiative called the Blue Brain project whereby they reconstructed the mammalian brain using simulations in order to generate a comprehension of the basic underlying principles of brain function and architecture. Computational Neuroscience becomes more relevant everyday and allows us to tackle difficult issues like the complexities of Hebbian Learning and Neural Networks. The implications of the field are perhaps unparalleled by any other fields of scientific inquiry, in that they may hold the answers to the creation of true Artificial Intelligence and the understanding of Consciousness and perception in the human brain. 3.7 Summary Figure 3.4: Applying Hebbian theory to computational neuroscience allows us to envision the connections between various neurons in the brain, displayed here is what is called a ‘connectome’. Every person has a brain, but that doesn’t mean we understand what the brain is, or what it does. The brain is a complex organism with many facets to understand, and to fully comprehend; one must understand the mechanics and the reasoning behind each component. Whether studying in a top-down process, or a bottom-up process, one must keep in mind Marr’s three levels of investigation: computational theory, representation and algorithm, and hardware and implementation. Computers and brains are different organisms, but by studying them alongside one another, a deeper understanding can be elicited. Turing introduced the world to the concept of using humans as a test of how to understand artificial intelligence, but we can now use artificial intelligence to understand the brain as well. 3.8 Exercises: Try out Conway’s Game of Life at https://bitstorm.org/gameoflife/ to explore more into the implications of the Turing Machine and computer simulations. What are at least two methods you could use to add two two integers such as 5 and 5? Now consider how you solved these two problems. Which of Marr’s levels was changing? Explain the difference between the top-down and bottom-up philosophy. Which better explains and represents cognitive phenomena: the top-down approach, or the bottom-up approach? Characterize the concept of emergent phenomena. Is human sentience that kind of phenomenon? Does artificial intelligence have to have emotions to be sentient? See https://plato.stanford.edu/entries/chinese-room/ for more on this thought experiment.↩︎ E.g. Dennett, Thagard, and Pinker to name a few.↩︎ "],
["Ch3.html", "4 Passive Membrane Models 4.1 Vocabulary 4.2 Introduction 4.3 What is an action potential? 4.4 Nernst equilibrium potential 4.5 Leaky Integrate and Fire Model 4.6 Summary 4.7 Exercises", " 4 Passive Membrane Models 4.1 Vocabulary Depolarization Positive Feedback Hyperpolarization Negative Feedback Membrane Potential Sodium-Potassium Pump Nernst Potential Reversal Potential Equilibrium Potential Driving Force Conductance Leak Current Leaky Integrate and Fire Model 4.2 Introduction 4.3 What is an action potential? Before going into ways of modeling action potentials, let’s further explore what an action potential is. Within a cell, there are more sodium ions outside the membrane, which have a positive charge. Because there are less positive ions inside the cell compared to the outside, the inside of the cell has a negative resting potential. When there is a spike of voltage, that causes both voltage-gated sodium and potassium channels–meaning that these channels activate and inactivate at certain voltages–to activate on a neuron’s membrane. However, the sodium channels open much faster than the potassium channels. The flow of sodium ions into the cell causes the membrane potential to become more positive. This process of positive ions flowing into the cell is called depolarization. When depolarization happens, it causes additional sodium channels to open, which causes further depolarization—this phenomenon is called positive feedback, and the positive feedback starts if the depolarization hits a set threshold. In other words, a positive feedback loop is a process that perpetuates itself. The positive feedback loop ends once voltage-gated potassium channels also open at the peak of the action potential and potassium begins flowing out of the cell and ending depolarization, we call this repolarization. When the voltage is below the resting potential, we call this undershoot hyperpolarization, which is when the membrane potential decreases towards a move negative value via potassium ions flowing out. As the voltage-gated potassium channels open and the voltage-gated sodium channels to close or become inactivated, there is now negative feedback. Negative feedback is a process by which an initial change is opposed by a force caused by the initial change. In this situation, the positive feedback causes a spike in membrane potential and the negative feedback stabilizes. Figure 4.1: A cell at rest has more potassium ions intracellular than extracellular and more sodium ions extracellular than intracellular. There is a negative net charge within the cell being maintained by the voltage gradient. Figure 4.2: When the cell becomes depolarized sodium ions enter the cell. The charge within the cell becomes more positive. Figure 4.3: When the cell repolarizes potassium ions leave the cell. The charge within the cell go from positive to negative as it goes back to the resting state. Figure 4.4: Example of an action potential. 4.4 Nernst equilibrium potential The electrical activity generated in a neuron is a result of ions flowing across the neuron’s membrane which is caused by the following two principles: opposite charges attract, and concentration gradients seek to equalize. This potential difference is referred to as the membrane potential. In order for ions to flow, a concentration gradient must be established because the difference in concentration across the membrane leads it to pass either into the neuron or out of the neuron. This is accomplished by the sodium-potassium pump, which uses just below 10% of your body’s daily energy to pump three sodium ions out of the neuron for every two potassium ions pumped in, thus forming two respective concentration gradients. With the concentration gradient established, the sodium and potassium ions will flow down the concentration gradients when their respective channels open, generating an electrical current that propagates down the axon. We must also take into account the fact that each ion possesses a charge–or charges in the case of Ca++ and Mg++–and that as this charge is built up on one side of the cell, this will generate an electrical force that will begin to repel ions with similar charge as they try to flow down their concentration gradient. When the force of the concentration gradient matches the electrical force attracting or repelling the ion, this is known as the Nernst potential for that ion, also referred to as the reversal potential. This means that means that both sodium and potassium possess their own respective Nernst potentials. Nernst potentials are especially important because they allow us to calculate the membrane voltage when a particular ion is in equilibrium, which helps to define the role it plays in an action potential. The Nernst potential for an ion can be derived from the following equation: \\[E_{ion} = \\frac{RT}{zF}ln(\\frac{[out]}{[in]}) \\] Expression Meaning \\(E_{ion}\\) Nernst potential R Gas constant: 8.314 \\(J/mol \\cdot K\\) ln() Natural log z Valence T Temperature in Kelvin F Faraday constant: 96485.3 C/mol [out] Extracellular ion concentration [in] Intracellular ion concentration While the Nernst potential will give the equilibrium point for a single ion, it also has a relation to the equilibrium potential or the resting potential the membrane, which is potential at which there is no net flow of ions, leading to a halt in the flow of electric current. The equilibrium potential is really a weighted average of all of the Nernst potentials and is modeled by the Goldman-Hodgkin-Katz equation which is shown below: \\[V_{m} = \\frac{RT}{F}ln(\\frac{P_{K}[K+]_{out}+P_{Na}[Na+]_{out}+P_{Cl}[Cl-]_{in}}{P_{K}[K+]_{in}+P_{Na}[Na+]_{in}+P_{Cl}[Cl-]_{out}}) \\] This equation utilizes the membrane permeability, P, in conjunction with the concentration of each ion inside and outside of the cell to produce the equilibrium potential of a membrane. Using this equation alongside the Nernst potential, the driving force, which is a representation of the pressure for an ion to move in or out of the cell, can be calculated using the following equation: \\[DF = V_{m}-E_{ion} \\] The Nernst Potential, the Goldman-Hodgkin-Katz equation, and the driving force present necessary calculations that allow for better understanding of the flow of ions in relation to an action potential. Worked Example: Consider the following table of ion concentrations and relative permeabilities: Ion Intracellular concentration (mM) Extracellular concentration (mM) Permeability K+ 150 4 1 Na+ 15 145 0.05 Cl- 10 110 0.45 If the extracellular concentration of Na+ was increased by a factor of ten: a. What is the new Nernst potential for sodium? b. What is the resting potential of the neuron? Solution, part a The Nernst equation is: \\(E_{ion} = \\frac{RT}{zF}ln\\frac{[ion]_{outside}}{[ion]_{inside}}\\) in which: R is the ideal gas constant: 8.314 \\(kg \\cdot m^2 \\cdot K^{1} \\cdot mol^{-1}s^{-2}\\) T is the temperature in Kelvin: (310 K at human temperature) z is the valence. Here, we use +1 because the Na+ ion has a charge of +1. F is Faraday’s constant: 96.49 \\(kJ \\cdot V^{-1} \\cdot mol^{-1}\\) Extracellular sodium is increased by a factor of 10: \\([Na+]_{outside}\\) = 10 * 145 mM = 1450 mM. From these values: \\[E_{Na+} = \\frac{8.314 \\cdot 310}{1 \\cdot 96.49} \\cdot \\ln \\frac{1450}{15}\\] \\[E_{Na+} = \\frac{2577.34}{96.49} \\cdot \\ln(96.67)\\] \\[E_{Na+} = 26.7109545 * (4.5713031) = 122.1 mV\\] Therefore, if the extracellular concentration of sodium was increased tenfold, the new Nernst potential for sodium would be 122.1 mV. Solution, part b: We will use the Goldman Hodgkin Katz (GHK) equation to find the resting potential of the neuron: \\[V_{m} = \\frac{RT}{F}ln(\\frac{P_{K}[K+]_{out}+P_{Na}[Na+]_{out}+P_{Cl}[Cl-]_{in}}{P_{K}[K+]_{in}+P_{Na}[Na+]_{in}+P_{Cl}[Cl-]_{out}}) \\] From the values given above: \\[V_{rest} = \\frac{8.314 \\cdot 310}{1 \\cdot 96.49} \\cdot \\ln \\frac{(.05*1450)+(1*4)+(.45*10)}{(.05*15)+(1*150)+(.45*110)}\\] \\[V_{rest} = \\frac{2577.34}{96.49} \\cdot \\ln \\frac{72.5+4+4.5}{75+150+49.5}\\] \\[V_{rest} = 26.71099545 \\cdot \\ln \\frac{81}{200.25} = -24.18 mV\\] If the extracellular concentration of sodium was increased by a factor of 10, the neuron’s resting potential would be -24.2 mV instead of -70 mV. Worked Example: Consider the unicorn neuron’s resting potential. Due to their mythical identity and magic, the resting potential for a unicorn neuron is different than that of humans. Unlike humans, unicorns have a magic ion that alters their resting potentials. The relevant ion concentrations and permeabilities are found in the table below: Ion Intracellular concentration (mM) Extracellular concentration (mM) Permeability K+ 150 4 1 Na+ 15 145 0.05 Cl- 10 110 0.45 Magic+ 200 30 1.1 What is the Nernst potential for the magic ion of the unicorn neuron, assuming magic+ moves just as other ions do? What is the resting potential of the unicorn neuron? Solution, part a: The Nernst equation is: \\(E_{ion} = \\frac{RT}{zF}ln\\frac{[ion]_{outside}}{[ion]_{inside}}\\) in which: R is the ideal gas constant: 8.314 \\(kg \\cdot m^2 \\cdot K^{1} \\cdot mol^{-1}s^{-2}\\) T is the temperature in Kelvin: (310 K at human temperature) z is the valence. Here, we use +1 because the Magic+ ion has a charge of +1. F is Faraday’s constant: 96.49 \\(kJ \\cdot V^{-1} \\cdot mol^{-1}\\) Extracellular sodium is increased by a factor of 10: \\([Na+]_{outside}\\) = 10 * 145 mM = 1450 mM. From these values: \\[E_{Na+} = \\frac{8.314 \\cdot 310}{1 \\cdot 96.49} \\cdot \\ln \\frac{30}{200}\\] \\[E_{Na+} = \\frac{2577.34}{96.49} \\cdot -1.90 = -50.8 mV\\] The Nernst potential of the magic+ ion is -50.8 mV. Thus the ionic and concentration gradients are at equilibrium for the magic+ ion when the potential difference of the neuron is -50.8 mV. Solution, part b: Here, we will expand the Goldman Hodgkin Katz equation to include the magic+ ion: \\[V_{m} = \\frac{RT}{F}ln(\\frac{P_{K}[K+]_{out}+P_{Na}[Na+]_{out}+P_{Cl}[Cl-]_{in} +P_{Magic}[Magic+]_{out}}{P_{K}[K+]_{in}+P_{Na}[Na+]_{in}+P_{Cl}[Cl-]_{out}+P_{Magic}[Magic+]_{in}}) \\] From the values given in part a: \\[V_{rest} = \\frac{8.314 \\cdot 310}{1 \\cdot 96.49} \\cdot \\ln \\frac{(.05*1450)+(1*4)+(.45*10)+(1.1*30)}{(.05*15)+(1*150)+(.45*110)+(1.1*200)}\\] \\[V_{rest} = \\frac{2577.34}{96.49} \\cdot \\ln \\frac{72.5+4+4.5+33}{75+150+49.5+220}\\] \\[V_{rest} = \\frac{2577.34}{96.49} \\cdot \\ln \\frac{72.5+4+4.5}{75+150+49.5}\\] \\[V_{rest} = 26.71099545 \\cdot \\ln \\frac{48.75}{420.25} = -57.3 mV\\] The resting potential of the unicorn neuron is -57.3 mV. This happens as a result of the permeabilities and concentrations of all four ions in this example, especially as a result of the magic+ ion’s high permeability. This makes the resting potential most similat to its Nernst potential. 4.5 Leaky Integrate and Fire Model Worked Example: Deriving the Integrate and Fire Model In the leaky integrate and fire model, we are modeling the membrane as a resistor-capacitor (RC) circuit and injecting into the cell some external current, \\(I_e\\). By Kirchhoff’s rule, we know that the the sum of all currents sums to zero. This means that the external current is the sum of a resistive current and a capactive current: \\[I_e = I_R + I_C\\] The resistive current is the current that flows through ion channels. Therefore, by Ohm’s law, it is the product of the membrane conductance (\\(g_L\\)) and the driving force (the difference between the present membrane potential, \\(V_m\\), and the resting membrane potential, \\(E_L\\)): \\[I_R = g_L(V_m-E_L)\\] Because the cell is negatively charged with respect to the outside, and because the membrane is very thin, negative charges build up along the inside of the membrane and attract positive charges on the outside. This means that the membrane is acting as a capacitor! The amount of charge (Q) that can be stored by the membrane is given by the capacitance equation: \\[C_mV_m = Q\\] Where \\(C_m\\) is the specific capacitance of the membrane, or its ability to store charge. Therefore, the capacitive current is: \\[I_C = \\frac{dQ}{dt} = C_m\\frac{dV_m}{dt}\\] Putting this all together, we get: \\[ C_m \\frac{dV_m}{dt} = I_e - g_L(V_m-E_L)\\] Ultimately, we want to solve for \\(V_m\\), so let’s first multiply both sides by \\(R_m\\). \\[ \\tau_m \\frac{dV_m}{dt} = R_m I_e + E_L-V_m\\] This is because the time constant, \\(\\tau_m\\) is equal to the product of \\(R_m C_m\\). We need to solve this differential equation for \\(V_m\\). We can see from the above equation that the change in membrane potential is some fraction of the difference between the present membrane potential \\(V_m\\) and \\(R_m I_e + E_L\\). Therefore, we know that the membrane will approach \\(R_m I_e + E_L\\) over time. We will therefore define this as the steady-state voltage \\(V_\\infty\\). Therefore, the solution to V(t) is: \\[V(t) = V_\\infty + (V(0)-V_\\infty)e^{\\frac{-dt}{\\tau_m}}\\] Where V(0) refers to the previously calculated voltage. This is the equation we have been working towards! Let’s perform some hand calculations. This is not efficient by any means, and this illustrates the application and practicality that computer programming has to offer neuroscience. Let’s first compute V(t) from a resting potential V(0) of -70 mV when there is no injected current. Recall that: \\[V_\\infty = R_m I_e +E_L\\] If there is no injected current (\\(I_e=0\\)), then \\(V_\\infty=E_L = -70 mV\\). Therefore, V(t) is equal to the resting potential when there is no injected current. Let’s use this equation to now calculate V(t) at the moment that \\(I_e\\) is turned on to 0.5 nA. Let’s start with \\(V_\\infty\\): \\[V_\\infty = 10 M \\Omega \\cdot 0.5 nA - 70 mV = -65 mV\\] This means that if we left the external stimulation on for a long time, the membrane would reach -65 mV. Let’s put this into the full equation using a \\(\\tau_m = 10 ms\\) and a dt of 0.1 ms. \\[ V(t) = -65 mV + (-70 mV - -65 mV)e^{\\frac{-.1}{10 ms}}\\] \\[V(t) = -65 mV + (-5)*.99 = -69.95 mV\\] In this way, we can work through, voltage by voltage, using the present voltage to calculate the next. But computers make this process much faster as you will see below. Worked Example: Johnny Firehydrant has just begun an investigative neurological study, focusing on memory. He has been trying to develop a model of how the hippocampus fires. Johnny’s model will begin with the CA1 neurons. He decided that this was an important place to begin because it receives inputs from CA2 and CA3 regions and it also outputs information to the Entorhinal cortex and the Subiculum; so the behavior of receiving, integrating, and firing is crucial for modelling the hippocampus. Using the leaky integrate-and-fire model of neuron ‘A’, run a simulation for 500 ms in time increments of 0.05 ms starting at the membrane’s resting potential of -70 mV. For the first 100 ms, Johnny is using a 0.5 nA injected current, from 125 ms to 200 ms he injects 1.3 nA, and between 250 ms and 350 ms the injected current is increased to 2.0 nA. You may assume the following values: \\(R_m = 10 M\\Omega\\) \\(\\tau_m = 10 ms\\) \\(V_{threshold} = -55 mV\\) \\(V_{reset} = -75 mV\\) \\(V_{spike} = 20 mV\\) Before we begin, here is a key of symbols and their meaning: \\(\\tau_m\\): The membrane time constant. \\(I_e\\): The external current that is injected into cell. \\(E_m\\): The membrane’s resting potential. \\(R_m\\): The membrane resistance. \\(g_L\\): Leak conductance. \\(V_m\\): Membrane potential. Step 1: Import numpy and matplotlib libraries for Python operations. Then assign variables to the parameter values provided above. # Import essential libraries import numpy as np import matplotlib.pyplot as plt # Set simulation parameters Vthresh = -55 #mV Vreset = -75 #mV Vspike = 20 #mV Rm = 10 #MOhms tau = 10 #ms dt = 0.05 #ms counter = 0 Step 2: Next, we will set up the data structures for holding our data. # Creates a vector of time points from 0 to 499 ms in steps of dt=0.05 timeVector = np.arange(0, 500, dt) # Creates a placeholder for our voltages that is the same size as timeVector voltageVector = np.zeros(len(timeVector)) # Creates a placeholder for the external stimulation vector. # It is also the same size as the time vector. stimVector = np.zeros(len(timeVector)) Step 3: We will now set our initial conditions # Set the initial voltage to be equal to the resting potential voltageVector[0] = Vrest Step 4: At this point you want to arrange Johnny’s applied current pulses according to time. (remember that the dt=0.05, so there are 20 time points per millisecond.) # Sets the external stimulation to 0.5 nA for the first 100 ms stimVector[0:2000] = 0.5 # Sets the external stimulation to 1.3 nA between 125 and 250 ms stimVector[2500:4000]= 1.3 # Sets the external stimulation to 2.0 nA between 250 and 350 ms stimVector[5000:7000] = 2.0 Step 5: Use a for-loop to use the present voltage value to compute the next voltage value. # This line initiates the loop. &quot;S&quot; counts the number of loops. # We are looping for 1 less than the length of the time vector # because we have already calculated the voltage for the first # iteration. for S in range(len(timeVector)-1): # Vinf is set to equal the resting potential plus the product # of the stimulation vector at the Sth time point. Vinf= Vrest + Rm * stimVector[S] # The next voltage value is is equal to where we are going (Vinf) # plus the product of the different between the present voltage and # Vinf (how far we have to go) and e^-t/tau (how far we are going # in each step) voltageVector[S+1] = Vinf + (voltageVector[S]-Vinf)*np.exp(-dt/tau) # This &#39;if&#39; condition states that if the next voltage is greater than # or equal to the threshold, then to run the next section if voltageVector[S+1] &gt;= Vthresh: # This states that the next voltage vector will be the Vspike value voltageVector[S+1] = Vspike # This &#39;if&#39; statement checks if we are already at Vspike (this is # another way we can be above Vthresh) if voltageVector[S] == Vspike: # Set the next voltage equal to the reset value voltageVector[S+1] = Vreset # This will count the number of observed spikes so that spike count # rate may be calculated later counter += 1 Step 6: Now, we just have to plot the simulation. # This sets the new plot object plt.figure() # This plots the voltage (y-axis) as a function of time (x-axis) plt.plot(timeVector, voltageVector) # This labels the y-axis plt.ylabel(&#39;Voltage in mV&#39;) # This labels the x-axis plt.xlabel(&#39;Time in ms) # This sets the title plt.title(&#39;Voltage versus time) The final graph looks like this: Figure 4.5: Output of sample code Step 7: Explore your simulation Now that you have designed an algorithm to plot Johnny’s experiment you are capable of learning a few characteristics of the design. For example, if you are curious about the voltage at a particular time step, you can read it out of the voltage vector. For instance, if you wanted to know the voltage at time point 2540 you would type: print(voltageVector[2540]) If you wanted to change the strength of the applied stimulation, or the duration of each pulse, you may edit these lines: stimVector[0:2000] = 0.5 stimVector[2500:4000]= 1.3 stimVector[5000:7000] = 2.0 Worked Example: Johnny has now developed a general model of how a hippocampal neuron fires. But Mr. Firehydrant wants to know how both the length of the stimulation pulse and the strength of that pulse interact to influence the neuron’s firing. Johnny devises the following stimulation protocol: At time zero, the cell is at rest. When the cell is not being stimulated, it is allowed to go back to rest. At 0.5 ms, 5 nA of current is injected into the cell for one time step. From 50 to 54 ms, 5 nA are injected into the cell. At 150 ms, the applied current is turned back on at 15 nA for one time step. From 200 ms to 202 ms, the current is held at 15 nA. At 250 ms, there is a 30 nA pulse of injected current for one time step. From 300 to 301 ms, the applied current is 30 nA. This appears more difficult than it is, and much of what you did for the previous example will help here. Graph the cell’s voltage over time as well as the external current over time. Notice how increasing the duration of the current pulse provides an additive effect in bringing the cell’s membrane potential closer to threshold. Most of your previous simulation can be recycled in full. You will make changes to two sections: defining your stimulation vector, and in adding a second graph. Here, we set the stimulation protocol. # Begin by setting the default stimulation level to 0 stimVector = np.zeros(len(timeVector)) # At 0.5 ms, 0.5 nA of current is injected stimVector[1] = 5 # From 50 to 54 ms, 5 nA are injected into the cell stimVector[999:1080] = 5 # At 150 ms, 15 nA is injected for one time step stimVector[2999] = 15 # From 200-202 ms, the current is held at 15 nA stimVector[3999:4040] = 15 # A pulse of 30 nA at 250 ms stimVector[4999] = 30 # From 300 to 301 ms, the applied current is 30 nA stimVector[5999:6020] = 30 And this code snippet creates our two plots. # This sets the plot object plt.figure() # This defines that we are plotting into the top plot plt.subplot(2,1,1) # two rows, one column, first graph # Plots time on the x-axis and current on the y-axis plt.plot(timeVector, stimVector) # Labels the x-axis plt.xlabel(&#39;Time in ms&#39;) # Labels the y-axis plt.ylabel(&#39;External current in nA&#39;) # Titles the plot plt.title(&#39;External Stimulation vs Time&#39;) # This defines that we are plotting into the top plot plt.subplot(2,1,2) # 2 rows, 1 column, 2nd graph # Plots time on the x-axis and voltage on the y-axis plt.plot(timeVector, voltageVector) # Labels the x-axis plt.xlabel(&#39;Time in ms&#39;) # Labels the y-axis plt.ylabel(&#39;Membrane potential in mV&#39;) The plot looks like this: Figure 4.6: Output of sample code 4.6 Summary 4.7 Exercises 4.7.1 Conceptual Exercises Describe the life cycle of an action potential. Be sure to include changes in channels/pumps, ion movement, and voltage. Explain why the resting potential is a steady state and how ion permeability and Nernst potential play a role. What does the Goldman-Hodgkin-Katz (GHK) equation tell you and when should it be used? What are the different ways molecules can move across the membrane of the neuron? Water flow abides by similar rules as ions flowing across a membrane in a neuron. Match each aspect of ion flow to water flow below. Explain your reasoning. Explain how depolarization and hyperpolarization relate to positive/negative feedback. Figure 4.7: Match each part of the water flow in this dam to ion flow in a neuron. Water Concept Neural Concept Water Voltage-gated channel Dam Ions Jet Ion pump Explain the basic function of the leaky integrate and fire model. Your response should describe both the RC membrane circuit as well as the logical rules governing the model neuron’s firing. Describe one aspect of the leaky integrate and fire model that is not biologically realistic. Briefly explain the concept of driving force. Explain the difference between the membrane potential, Nernst potential and equilibrium potential. 4.7.2 Coding Exercises Let us walk through calculating the Nernst potential in Python. 1. Shown below is the Nernst equation that allows us to calculate the Nernst potential (AKA: reversal potential, resting potential) of the crucial ions (Na+, K+, Cl-) in our body that make action potentials possible. \\[E_{ion} = \\frac{RT}{zF}ln(\\frac{[out]}{[in]}) \\] Okay, I know this equation may seem to be made up of lots of different variables, but it really is not. Let’s break it down together: R and F are both constants. T is our body temperature. So, \\(\\frac{RT}{F}\\) is about 26.5 mV. z is the charge of the given ion. (Hint: Na+: +1, K+: +1; Cl-: -1) [out] and [in] refer to the ion concentrations on the extracellular, and intracellular sides of the membrane, respectively. Our goal is to create a general Python function that will predict whether the Nernst potential for Na+, K+, or Cl- will be positive or negative. The advantage of writing a function is that we will be able to write one piece of code that can be re-used for each ion by substituting in the relevant values. Right now, we only care about the relative concentrations, so we can just use 1 to represent the side with the lower concentration, and 2 for the side with the higher ion concentration. Use the following steps to construct your function: Open a blank Jupyter notebook. Import the necessary Python libraries. (Hint: numpy is useful for calculation. In Python, ln() implemented in the log() function) Set up the general function definition. (Hint: Use “def” and “return” to set up a function named “Eion” with three arguments. The constants in the Nernst equation will not affect our results, so we may omit them for now.) Try out your function for each of the three major ions and print out the results. (Hint: Think about the relative concentration of each ion inside and outside of the neuron during the resting state. Remember that Cl- is tricky!) Good job! Now, let’s apply your function to calculate more realistic Nernst potentials for Na+, K+, and Cl- given their actual ionic concentrations: Ion Intracellular concentration (mM) Extracellular concentration (mM) Na+ 15 145 K+ 150 4 Cl- 10 110 Pro-tip: We are still using the same Jupyter notebook as part (a), we do not have to import numpy again! Lazy is good. Use the following steps to apply your function: Set up the general function. (Hint: alter your Eion function to use the R and F constants as well.) Use the values from the table in order to print out the Nernst potential for each ion. Sort the Nernst potentials from smallest to largest. Print the name of the ion that is closest to the neuron’s resting potential (-65 mV). As we previously learned, the resting potential of the neuron can be predicted by the Goldman Hodgkin Katz (GHK) equation as follows: \\[V_{m} = \\frac{RT}{F}ln(\\frac{P_{K}[K+]_{out}+P_{Na}[Na+]_{out}+P_{Cl}[Cl-]_{in}}{P_{K}[K+]_{in}+P_{Na}[Na+]_{in}+P_{Cl}[Cl-]_{out}}) \\] The first part of the equation looks similar to the Nernst equation - great! \\[V_{m} = 26.5 \\cdot \\ln(\\frac{P_{K}[K+]_{out}+P_{Na}[Na+]_{out}+P_{Cl}[Cl-]_{in}}{P_{K}[K+]_{in}+P_{Na}[Na+]_{in}+P_{Cl}[Cl-]_{out}}) \\] But what the heck is going on inside the parentheses? The resting potential is dependent on and made up of these three ions. Therefore, we are weighting each ion according to its relative permeability value. The relative permeability value reflects the ease with which each ion can pass through the membrane at rest. By convention, we assign \\(P_{K+}\\) to be 1. The membrane is far less permeable to sodium (\\(P_{Na+} = 0.05\\)), and moderately permeable to chloride (\\(P_{Cl-} = 0.45\\)). These values reflect the relative density of leak channels for K+, Na+, and Cl- in the membrane. Create a general Python function to calculate the resting potential of a neuron from the previously provided values. Use the following steps: Import the necessary Python libraries. Set up the general function. There are six different concentrations that can be considered as input arguments. For simplicity, you may “hard code” the permeability of Na+ and K+ inside your function. Please put Cl- permeability as an argument to your function because you will use it in the next question. (Hint: take a close look at the equation. Cl- is different!) Early in development (when we were babies), it is found that intracellular concentration of Cl- ions is higher than the extracellular concentration of Cl-. This is due to the delayed expression of Cl- exporters in the membrane. All else being equal, how would this affect the resting potential? Would the neuron be more or less likely to fire an action potential in this state? To simplify, assume that \\(p_{Cl} = 0.1\\) because there are fewer exporters. Let’s assume that [ion] and [out] are switched for this problem. "],
["Ch4.html", "5 Hodgkin and Huxley Model 5.1 Vocabulary 5.2 Introduction 5.3 The Hodgkin and Huxley model 5.4 Summary 5.5 Exercises:", " 5 Hodgkin and Huxley Model 5.1 Vocabulary Depolarization Positive Feedback Hyperpolarization Negative Feedback Membrane Potential Sodium-Potassium Pump Nernst Potential Reversal Potential Equilibrium Potential Driving Force Conductance Leak Current Leaky Integrate and Fire Model Absolute Refractory Period Gating variable 5.2 Introduction Before you read this chapter, we would like to draw your attention to this video. We call this a Zombie Squid because the squid is in fact dead; however, it is recently deceased. Since the squid passed shortly before, Adenosine triphosphate (ATP) energy stores are still available to the squid’s muscles. When the soy sauce, which has a lot of sodium chloride (salt) in it, is poured onto the squid, the salt in the soy sauce causes a voltage change which causes the squid’s muscles to contract. Thus, we have a Zombie Squid. So why is the Zombie Squid important? The Hodgkin-Huxley Model, said to have started the field of computational neuroscience, all hinges on the giant axons of squid. In the 1950s Alan Hodgkin and Andrew Huxley built a model that shows us how computers can successfully predict certain aspects of the brain that cannot be directly studied. The two even won a Nobel Prize in Physiology or Medicine in 1963 with Sir John Carew Eccles for their model. The Hodgkin-Huxley Model is now the basis of all conductance-based models. As a result, we can now understand how an action potential works, and why it is an all-or-none event. While Hodgkin and Huxley created their model in the 1950s, the first recording of an action potential was done by Edgar Adrian in the 1920s. However, the first person to realize that neurons communicate via electrical signals came much earlier in 1791, when Luigi Galvani found that electricity from lightning or primitive batteries can cause a dead frog’s leg muscle to contract. This led to a good amount of Frankenstein-like science with interested parties running electricity through dead bodies in an attempt to bring them back to life. However, the next truly scientific discovery came from Hermann Helmholtz in the 19th century. Helmholtz found that he could measure the speed of muscles contracting when he stimulated the nerve linked to that specific muscle. The Hodgkin-Huxley Model was then created once Adrian noted that not only were action potentials discrete, but the firing rate (spike per second) increased as stimulation to the nerve increased. 5.3 The Hodgkin and Huxley model Figure 5.1: Alan Hodgkin (left) and Andrew Huxley (right). Alan Hodgkin (pictured left) and Andrew Huxley (pictured right) were two Cambridge University undergraduates who eventually found themselves working in a marine biology laboratory with the axon of a giant squid. The two men were able to derive the necessary information for their influential model of an action potential using the massive axon of the giant squid. Hodgkin and Huxley developed a series of equations that could accurately predict and depict action potentials. Their work is a cornerstone for computational modeling as computer modelling can now be used to mimic the biological properties of a neuron that we are unable to directly observe. Really the Hodgkin-Huxley Model is just an elaboration on the Integrate and Fire Model. The Integrate and Fire model was generated by French neuroscientist Louis Lapicque, who in 1907 sought to generate a mathematical model that could be used to predict and graph an action potential. In his efforts to understand action potentials, Lapicque chose to model the flow of ions as a single leak current. Hodgkin and Huxley took the single conductance term from the Integrate and Fire Model is broken up into three separate conductance terms, each relating to a different ion channel. These conductance terms are known as gating variables and are labeled m, n, and h. Voltage-gated sodium channel activation is modeled by the letter ms. Voltage-gated sodium channels have three subunits, as these three subunits are involved in the channels activation, m is raised to the third power. Voltage-gated sodium channel also inactivate at the peak of the action potential and this variable is modeled by the letter h. The combination of m and h gives rise to the conductance of Voltage-gated sodium channel which is modeled below: \\[\\bar{g}_{Na}m^{3}h(V(t)-E_{Na}) \\] Voltage-gated potassium channels are modeled by the letter n. Voltage-gated potassium channels have four subunits, and thus the gating variable, n, is raised to the fourth power. The conductance of Voltage-gated potassium channels is modeled below: \\[\\bar{g}_{K}n^{4}(V(t)-E_{K} \\] The final conductance taken into account by Hodgkin and Huxley is the leak potential of all the ions. The Leak conductance is taken into account for the instance when all ion channels are open. This conductance is represented below: \\[\\bar{g}_{L}(V(t)-E_{L}) \\] These three conductance variables are combined together to form the Hodgkin-Huxley equation which is written as follows: \\[C\\frac{dV}{dt}=I_{e}(t)-[(\\bar{g}_{Na}m^{3}h(V(t)-E_{Na}))+(\\bar{g}_{K}n^{4}(V(t)-E_{K}))+(\\bar{g}_{L}(V(t)-E_{L}))] \\] Expression Meaning n Potassium gating variable m Sodium activation gating variable h Sodium inactivation gating variable \\(C_m\\) Specific membrane capacitance \\(I_e\\) Injected current \\(\\bar{g}_{Na}\\) Maximum Na+ conductance \\(\\bar{g}_{K}\\) Maximum K+ conductance \\(\\bar{g}_{L}\\) Maximum leak conductance \\(V_m\\) Membrane potential \\(E_{Na}\\) Sodium Nernst potential \\(E_{K}\\) Potassium Nernst potential \\(E_{L}\\) Leak Nernst potential Additionally, we can calculate the value of each gating variable over different voltages and times: \\[m\\frac{dV}{dt} = \\alpha_{m}(V)(1-m)-\\beta_{m}(V)m \\] Both n and h can be substituted for m in the above equation in order to calculate values for each gating variable. Additionally, note the \\(\\alpha\\) and \\(\\beta\\) in the equation are rate constants that govern the opening and closing (respectively), of their channels. Here are their values: \\[ \\alpha_{n}(V_{m}) = \\frac{0.01(V_{m}+55)}{1-exp(-0.1(V_{m}+55))} \\] \\[\\alpha_{m}(V_{m}) = \\frac{0.1(V_{m}+40)}{1-exp(-0.1(V_{m}+40))}\\] \\[\\alpha_{h}(V_{m}) = 0.07exp(-0.05(V_{m}+65)) \\] \\[\\beta_{n}(V_m) = 0.125exp(-0.0125(V_{m}+65)) \\] \\[\\beta_{m}(V_{m}) = 4exp(-0.0556(V_{m}+65)) \\] \\[\\beta_{h}(V_{m}) = \\frac{1}{1+exp(-0.1(V_{m}+35))} \\] Expression Meaning \\(\\alpha_n\\) Rate constant for K+ channel opening \\(\\alpha_m\\) Rate constant for Na+ activation gate opening \\(\\alpha_h\\) Rate constant for Na+ inactivation gate opening \\(\\beta_n\\) Rate constant for K+ channel closing \\(\\beta_m\\) Rate constant for Na+ activation gate closing \\(\\beta_h\\) Rate constant for Na+ inactivation gate closing Worked Example: Have you ever wondered how anesthesia makes a tooth extraction painless? It’s because anesthesia works by blocking the activation of voltage-dependent Na+ channels. This prevents the propagation of the action potentials that carry that awful pain sensation. Using the equations below, calculate the maximum conductances of each ion in the resting state. Useful parameters: \\(V_m\\) = -68 mV \\(C_m\\) = -20.1 nF \\(E_L\\) = -54 mV \\(E_{Na}\\) = 50 mV \\(E_K\\) = -77 mV \\(R_L = 1/3 M\\Omega\\) \\(g_{Na} = 1200 mS/mm^2\\) Equations: \\[I_{ion} = g_{Na} \\cdot m^3h(V_m-E_{Na}) + g_K \\cdot n^4 (V_m-E_K) + g_L \\cdot (V_m-E_L)\\] \\[\\frac{dn}{dt} = \\alpha_n(V) \\cdot (1-n) - \\beta_n(V) \\cdot(n)\\] \\[\\frac{dm}{dt} = \\alpha_m(V) \\cdot (1-m) - \\beta_m(V) \\cdot(m)\\] \\[\\frac{dh}{dt} = \\alpha_h(V) \\cdot (1-h) - \\beta_h(V) \\cdot(h)\\] Step 1: Understand the question The resting potential can be considered to be a steady state because the voltage is not changing. Therefore, \\(\\frac{dp}{dt}=0\\) for p={n, m, h} and therefore the last three equations will not be used. Step 2: Calculate n, m, and h We need to now use the resting potential to solve for the steady state values of the gating variables. \\[p_\\infty = \\frac{\\alpha_p}{\\alpha_p+\\beta_p}\\] for p = {n, m, h} Therefore, the very first step is to calculate each \\(\\alpha\\) and \\(\\beta\\). \\[ \\alpha_{n}(V_{m}) = \\frac{0.01(V_{m}+55)}{1-exp(-0.1(V_{m}+55))} \\] \\[\\alpha_{n}(V_{rest}) = \\frac{0.01(-68+55)}{1-exp(-0.1(-68+55))} \\] \\[\\alpha_{n} = 0.049\\] \\[\\alpha_{m}(V_{m}) = \\frac{0.1(V_{m}+40)}{1-exp(-0.1(V_{m}+40))}\\] \\[\\alpha_{m}(V_{rest}) = \\frac{0.1(-68+40)}{1-exp(-0.1(-68+40))}\\] \\[\\alpha_{m}(V_{rest}) = 0.18\\] \\[\\alpha_{h}(V_{m}) = 0.07exp(-0.05(V_{m}+65)) \\] \\[\\alpha_{h}(V_{rest}) = 0.07 \\cdot exp(-0.05 \\cdot(-68+65)) \\] \\[\\alpha_{h}(V_{rest}) = 0.08\\] \\[\\beta_{n}(V_m) = 0.125exp(-0.0125(V_{m}+65)) \\] \\[\\beta_{n}(V_{rest}) = 0.125 \\cdot exp(-0.0125 \\cdot(-68+65)) \\] \\[\\beta_{n}(V_{rest}) = 0.13\\] \\[\\beta_{m}(V_{m}) = 4exp(-0.0556(V_{m}+65)) \\] \\[\\beta_{m}(V_{rest}) = 4 \\cdot exp(-0.0556 \\cdot(-68+65)) \\] \\[\\beta_{m}(V_{rest}) = 4.73\\] \\[\\beta_{h}(V_{m}) = \\frac{1}{1+exp(-0.1(V_{m}+35))} \\] \\[\\beta_{h}(V_{rest}) = \\frac{1}{1+exp(-0.1(-68+35))} \\] \\[\\beta_{h}(V_{rest}) = 0.036\\] Now, with each of our \\(\\alpha\\) and \\(\\beta\\) values, we can calculate our gating variables: \\[n_\\infty = \\frac{\\alpha_n}{\\alpha_n+\\beta_n}\\] \\[n_\\infty = \\frac{0.049}{0.049+0.13} = 0.274\\] \\[m_\\infty = \\frac{\\alpha_m}{\\alpha_m+\\beta_m}\\] \\[m_\\infty = \\frac{0.18}{0.18+4.73} = 0.037\\] \\[h_\\infty = \\frac{\\alpha_h}{\\alpha_h+\\beta_h}\\] \\[h_\\infty = \\frac{0.08}{0.08+0.036} = 0.690\\] Step 3: Calculate \\(g_L\\) from resistance units. Remember that \\(g = \\frac{1}{R}\\)! \\[g_L = (1/R) = (1/(1/3)) = 3 mS/mm^2\\] Step 4: Solve for \\(g_K\\) Remember that from Kirchhoff’s Law that the algebraic sum of all the currents entering and leaving a junction must be equal to 0. Therefore: \\[0 = g_{Na} \\cdot m^3h(V_m-E_{Na}) + g_K \\cdot n^4 (V_m-E_K) + g_L \\cdot (V_m-E_L)\\] And we may plug in the values that we already have: \\[0 = 1200 \\cdot 0.037^30.69 \\cdot(-68-50) + g_K \\cdot 0.274^4 \\cdot (-68--77) + 3 \\cdot (-68--54.387)\\] \\[0 = 4.956 + g_K \\cdot 0.051 + (-40.84)\\] \\[g_K = 703.6\\] Worked Example: The voltage of a neuron is clamped at -20 mV, depolarized from its resting potential of -65 mV. The steady-state values of the gating variables in the two conditions are shown below. Comment on what these changes mean for the neuron’s behavior. V=-65 mV V=-20mV m=0.0529 m=0.875 n=0.3177 n=0.820 h=0.5961 h=0.009 Answer The value of m represents the probability of voltage-gated Na+ channels to be open. This probability increases as the cell depolarizes. The n value represents the probability that the voltage-gated K+ channel is open. Like the Na+ channels, this probability increases with depolarization, but not to the same extent. The h values represent the probability of Na+ channel inactivation. This decreases significantly with depolarization because we have not hit the peak of the action potential. It is fair to assume that the h value will increase as we near the peak. 5.4 Summary An action potential is the electro-chemical signal that propagates down a neuron. Action potentials are facilitated by the electrochemical gradient that is maintained through the action of the Sodium-Potassium Pump. The role that each ion plays within the action potential can be determined through the use of the Nernst Equation, which allows us to understand the movement of a specific ion at a specific membrane voltage. Understanding the role of ions, is important, but this is not how we actually graph an action potential. One of the first modules developed to graph an action potential was the integrate and fire module. This equation disregarded all of the biomechanical features of an action potential and focused on the subthreshold membrane dynamics of a neuron. This model was relatively effective, until Hodgkin and Huxley reassessed it and changed the single leak resistance in integrate and fire to three separate resistance terms. Hodgkin and Huxley in doing this created an equation that more thoroughly analyzed and depicted the very action potential that is displayed to this day. 5.5 Exercises: 5.5.1 Conceptual Exercises: Briefly explain how the Zombie Squid moves. Why is this important to understand? Action potentials are characterized by both negative and positive feedback. Provide one example of each that takes place during an action potential. Describe one difference between the leaky integrate and fire model and the Hodgkin and Huxley model. Why does depolarization not continue indefinitely once voltage-gated Na+ channels have opened? Describe the specific stages of the action potential. How are these stages relate to positive/negative feedback? What kinds of channels are open/closed during the respective stages? 5.5.2 Coding Exercises: Welcome to the coding problems for the Hodgkin and Huxley model! These exercises will help you get comfortable with using the Hodgkin and Huxley Model in different settings. To get started, simply run the following cell to create a few custom functions that we will be using for these exercises. No changes are needed, but feel free to look through the code and descriptive comments to see how each aspect of the model is implemented! # Import necessary libraries import numpy as np import matplotlib.pyplot as plt #Creates a custom Hodgkin and Huxley function def HHmodel(Ie, dt, tFinal, tStimStart, tStimEnd, RestingPotential): import matplotlib.pyplot as plt # Defines the model parameters c = 10 # capacitance per unit area (nF/mm^2) gMaxL = 3 # leak maximal conductance per unit area (mS/mm^2) EL = -54.387 # leak conductance reversal potential (mV) gMaxK = 360 # maximal K conductance per unit area (mS/mm^2) EK = -77 # K conductance reversal potential (mV) gMaxNa= 1200 # maximal Na conductance per unit area (mS/mm^2) ENa = 50 # Na conductance reversal potential (mV) # sets up data structures to hold relevant variable vectors timeVec = np.arange(0,tFinal, dt) voltageVector = np.zeros(len(timeVec)) Ivector = np.zeros(len(timeVec)) mVec = np.zeros(len(timeVec)) hVec = np.zeros(len(timeVec)) nVec = np.zeros(len(timeVec)) tauVec = np.zeros(len(timeVec)) # assigns the initial value of each variable voltageVector[0] = RestingPotential mVec[0] = 0.0529 hVec[0] = 0.5961 nVec[0] = 0.3177 # defines the stimulus tStimStart = int(tStimStart/dt) tStimEnd = int(tStimEnd/dt) Ivector[tStimStart:tStimEnd] = Ie # For-loop integrates equations into model for v in range(len(timeVec)-1): # Calculates alpha values for m, h, and n alpha_n = 0.01*(voltageVector[v] + 55) / (1-np.exp(-0.1*(voltageVector[v]+55))) alpha_m = (0.1*(voltageVector[v]+40))/ (1-np.exp(-0.1*(voltageVector[v]+40))) alpha_h = 0.07*np.exp(-.05*(voltageVector[v]+65)) # Calculates beta values for m, h, and n beta_n = 0.125*np.exp(-.01125*(voltageVector[v]+55)) beta_m = 4*np.exp(-.05556*(voltageVector[v]+65)) beta_h = 1 / (1 + np.exp(-0.1*(voltageVector[v]+35))) # Calculates tau values for m, h, and n tau_n = 1 / (alpha_n + beta_n) tau_m = 1 / (alpha_m + beta_m) tau_h = 1 / (alpha_h + beta_h) # Calculates inf values for m, h, and n pm = alpha_m/(alpha_m + beta_m) pn = alpha_n/(alpha_n+ beta_n) ph = alpha_h/(alpha_h + beta_h) # Calculates and store values in m, h, and n vectors mVec[v+1] = pm + (mVec[v] - pm)*np.exp(-dt/tau_m) nVec[v+1] = pn + (nVec[v] - pn)*np.exp(-dt/tau_n) hVec[v+1] = ph + (hVec[v] - ph)*np.exp(-dt/tau_h) # Updates Vinf and tauV denominator = gMaxL + gMaxK*(nVec[v]**4) + gMaxNa*(mVec[v]**3)*hVec[v] tauV = c / denominator Vinf = ((gMaxL)*EL + gMaxK*(nVec[v]**4)*EK + gMaxNa*(mVec[v]**3)*hVec[v]*ENa + Ivector[v])/denominator # Calculates and store next voltage value in vector voltageVector[v+1] = Vinf + (voltageVector[v]-Vinf)*np.exp(-dt/tauV) # Plotting plt.figure(1, figsize=(10,10)) plt.subplot(4,1,1) plt.plot(timeVec,voltageVector) plt.title(&#39;Hodgkin and Huxley Simulation&#39;) plt.ylabel(&#39;Voltage in mV&#39;) plt.subplot(4,1,2) plt.plot(timeVec, mVec) plt.ylabel(&#39;g_Na activation variable m&#39;) plt.subplot(4,1,3) plt.plot(timeVec, hVec) plt.ylabel(&#39;g_Na inactivation variable h&#39;) plt.subplot(4,1,4) plt.plot(timeVec, nVec) plt.ylabel(&#39;g_K activation variable&#39;) plt.xlabel(&#39;Time in ms&#39;) #creates a custom function that will determine the minimum Ie # required to surpass the threshold potential def HHmodel_threshold(Ie): tStimStart = 250 tStimEnd = 750 dt = 0.1 # time step (ms) tFinal = 1000 # total time of run (ms) RestingPotential = -65 c = 10 # capacitance per unit area (nF/mm^2) gMaxL = 3 # leak maximal conductance per unit area (mS/mm^2) EL = -54.387 # leak conductance reversal potential (mV) gMaxK = 360 # maximal K conductance per unit area (mS/mm^2) EK = -77 # K conductance reversal potential (mV) gMaxNa= 1200 # maximal Na conductance per unit area (mS/mm^2) ENa = 50 # Na conductance reversal potential (mV) for current in range(len(Ie)): timeVec = np.arange(0,tFinal, dt) voltageVector = np.zeros(len(timeVec)) Ivector = np.zeros(len(timeVec)) mVec = np.zeros(len(timeVec)) hVec = np.zeros(len(timeVec)) nVec = np.zeros(len(timeVec)) tauVec = np.zeros(len(timeVec)) voltageVector[0] = RestingPotential mVec[0] = 0.0529 hVec[0] = 0.5961 nVec[0] = 0.3177 Ivector[2499:7499] = Ie[current] for v in range(len(timeVec)-1): alpha_n = 0.01*(voltageVector[v] + 55) / (1-np.exp(-0.1*(voltageVector[v]+55))) alpha_m = (0.1*(voltageVector[v]+40))/ (1-np.exp(-0.1*(voltageVector[v]+40))) alpha_h = 0.07*np.exp(-.05*(voltageVector[v]+65)) beta_n = 0.125*np.exp(-.01125*(voltageVector[v]+55)) beta_m = 4*np.exp(-.05556*(voltageVector[v]+65)) beta_h = 1 / (1 + np.exp(-0.1*(voltageVector[v]+35))) tau_n = 1 / (alpha_n + beta_n) tau_m = 1 / (alpha_m + beta_m) tau_h = 1 / (alpha_h + beta_h) pm = alpha_m/(alpha_m + beta_m) pn = alpha_n/(alpha_n+ beta_n) ph = alpha_h/(alpha_h + beta_h) mVec[v+1] = pm + (mVec[v] - pm)*np.exp(-dt/tau_m) nVec[v+1] = pn + (nVec[v] - pn)*np.exp(-dt/tau_n) hVec[v+1] = ph + (hVec[v] - ph)*np.exp(-dt/tau_h) denominator = gMaxL + gMaxK*(nVec[v]**4) + gMaxNa*(mVec[v]**3)*hVec[v] tauV = c / denominator Vinf = ((gMaxL)*EL + gMaxK*(nVec[v]**4)*EK + gMaxNa*(mVec[v]**3)*hVec[v]*ENa + Ivector[v])/ denominator voltageVector[v+1] = Vinf + (voltageVector[v]-Vinf)*np.exp(-dt/tauV) # Checks to see if the given current resulted in an # action potential # Values around 25 mv is only reached if the neuron spikes. # A value of 20 would similarly be appropriate if voltageVector[v] &gt; 25: return(print(&quot;With an external current of&quot;, Ie[current]-1 , &quot;nA/mm^2 threshold potential was finally reached!&quot;)) return(print(&quot;Looks like you didn&#39;t provide a large value in your range caused the neuron to spike. Try again!&quot;)) # plots the behavior of a neuron when injected with different # currents on the same graphs def HHmodel_compare(Ie, RestingPotential): terminate = 0 tStimStart = 10 tStimEnd = 30 tFinal = 50 dt = 0.002 c = 10 gMaxL = 0.003e03 EL = -54.387 gMaxK = 0.36e03 EK = -77 gMaxNa = 1.2e03 ENa = 50 for current in range(len(Ie)): timeVec = np.arange(0,tFinal, dt) voltageVector = np.zeros(len(timeVec)) Ivector = np.zeros(len(timeVec)) mVec = np.zeros(len(timeVec)) hVec = np.zeros(len(timeVec)) nVec = np.zeros(len(timeVec)) tauVec = np.zeros(len(timeVec)) voltageVector[0] = RestingPotential mVec[0] = 0.0529 hVec[0] = 0.5961 nVec[0] = 0.3177 Ivector[5000:15000] = Ie[current] for v in range(len(timeVec)-1): alpha_n = 0.01*(voltageVector[v] + 55) / (1-np.exp(-0.1*(voltageVector[v]+55))) alpha_m = (0.1*(voltageVector[v]+40))/ (1-np.exp(-0.1*(voltageVector[v]+40))) alpha_h = 0.07*np.exp(-.05*(voltageVector[v]+65)) beta_n = 0.125*np.exp(-.01125*(voltageVector[v]+55)) beta_m = 4*np.exp(-.05556*(voltageVector[v]+65)) beta_h = 1 / (1 + np.exp(-0.1*(voltageVector[v]+35))) tau_n = 1 / (alpha_n + beta_n) tau_m = 1 / (alpha_m + beta_m) tau_h = 1 / (alpha_h + beta_h) pm = alpha_m/(alpha_m + beta_m) pn = alpha_n/(alpha_n+ beta_n) ph = alpha_h/(alpha_h + beta_h) mVec[v+1] = pm + (mVec[v] - pm)*np.exp(-dt/tau_m) nVec[v+1] = pn + (nVec[v] - pn)*np.exp(-dt/tau_n) hVec[v+1] = ph + (hVec[v] - ph)*np.exp(-dt/tau_h) denominator = gMaxL + gMaxK*(nVec[v]**4) + gMaxNa*(mVec[v]**3)*hVec[v] tauV = c / denominator Vinf = ((gMaxL)*EL + gMaxK*(nVec[v]**4)*EK + gMaxNa*(mVec[v]**3)*hVec[v]*ENa + Ivector[v])/ denominator voltageVector[v+1] = Vinf + (voltageVector[v]-Vinf)*np.exp(-dt/tauV) # stores values so the two plots can be superimposed if terminate ==0: Mv = mVec Nv = nVec Hv = hVec Vv = voltageVector terminate = 1 #plotting plt.figure(1, figsize=(10,10)) plt.subplot(4,1,1) plt.plot(timeVec,voltageVector, timeVec, Vv) plt.title(&#39;Hodgkin and Huxley Simulation&#39;) plt.ylabel(&#39;Voltage in mV&#39;) plt.subplot(4,1,2) plt.plot(timeVec, mVec, timeVec, Mv) plt.ylabel(&#39;g_Na activation variable m&#39;) plt.subplot(4,1,3) plt.plot(timeVec, hVec, timeVec, Hv) plt.ylabel(&#39;g_Na inactivation variable h&#39;) plt.subplot(4,1,4) plt.plot(timeVec, nVec, timeVec, Nv) plt.ylabel(&#39;g_K activation variable&#39;) plt.xlabel(&#39;Time in ms&#39;) print(&quot;Cell run successfully! Please proceed to the next part&quot;) Problem 1: Exploring the Model Part 1 What can the model do? The function HHmodel() provides insight by simulating a neuron firing and the behavior of its channel gating variables under various conditions. Simulate an experiment that runs for 500 ms in which a neuron is exposed to a current of 100 \\(nA/mm^2\\) from 100-400 ms. Use time steps of 0.1 ms and set the resting potential to -65 mV. Note, the code has been started for you - set the variables to their specified values and run the code. tStimStart = # time to start injecting current (ms) tStimEnd = # time to end injecting current (ms) tFinal = # total time of run (ms) dt = # time step (ms) Ie = # nA/mm^2 RestingPotential = #mv # Run the custom function HHmodel(Ie, dt, tFinal, tStimStart, tStimEnd, RestingPotential) Part 2 Nice work! Does increasing the injected current increasing the firing rate? Using the same code, increase the injected current to 250 \\(nA/mm^2\\) to find out! Part 3, optional Play around with the parameters to see how changing the neuron’s starting conditions will affect its behavior! Problem 2: Threshold Potential Part 1 Neurons operate on a “all or nothing” basis. The function HHmodel_threshold() takes different values of injected currents (\\(I_e\\)) and returns the minimum value that elicited an action potential. Using np.arange(), set \\(I_e\\) equal to a vector of increasing voltages to determine the minimum injected current required for the neuron to cross its threshold potential. Hint: first define your external stimulation, \\(I_e\\) then use the HHmodel_threshold() function. Part 2 The function HHmodel_compare() will plot the behavior of a neuron and its gating variables for two different injected current values. The function’s input is the array \\(I_e\\) that contains two values. Using the external current determined in part one and the preceding integer, run the code to see the difference between just missing and passing the threshold potential! Part 3 Pretty striking difference right? Now imagine there is a neuron where the resting potential is -60 mV rather than -65. What would happen if all else remained equal? Change the resting potential to -60 mV and rerun the code to find out!(Note: HHmodel_compare() also accepts an input for the resting potential.) Problem 3: Pick your Poison(s) Part 1 The poisonous dart frog of Central and South America secretes the neurotoxin batrachotoxin (BTX). Exposure to BTX results causes paralysis by irreversibly binding to the sodium channels and preventing them from closing. In the following code, simulate a neuron’s exposure to BTX by setting the relevant variable to the appropriate value. Note: the only code that should be altered has been sectioned off using hashtags. # Define input parameters c = 10 gMaxL = 0.003e03 EL = -54.387 gMaxK = 0.36e03 EK = -77 gMaxNa = 1.2e03 ENa = 50 Ie = 200 tFinal = 1000 # Set up data structures timeVec = np.arange(0,tFinal, dt) voltageVector = np.zeros(len(timeVec)) Ivector = np.zeros(len(timeVec)) mVec = np.zeros(len(timeVec)) hVec = np.zeros(len(timeVec)) nVec = np.zeros(len(timeVec)) tauVec = np.zeros(len(timeVec)) # Initialize starting values voltageVector[0] = -65 mVec[0] = 0.0529 hVec[0] = 0.5961 nVec[0] = 0.3177 Ivector[1999:7999] = Ie # Loop to calculate next values for v in range(len(timeVec)-1): alpha_n = 0.01*(voltageVector[v] + 55) / (1-np.exp(-0.1*(voltageVector[v]+55))) alpha_m = (0.1*(voltageVector[v]+40))/ (1-np.exp(-0.1*(voltageVector[v]+40))) alpha_h = 0.07*np.exp(-.05*(voltageVector[v]+65)) beta_n = 0.125*np.exp(-.01125*(voltageVector[v]+55)) beta_m = 4*np.exp(-.05556*(voltageVector[v]+65)) beta_h = 1 / (1 + np.exp(-0.1*(voltageVector[v]+35))) ############# # if timeVec[v] &gt;= 300: # = # Part one # if timeVec[v] &gt; 600: # = # Part two ############## # Update time constants tau_n = 1 / (alpha_n + beta_n) tau_m = 1 / (alpha_m + beta_m) tau_h = 1 / (alpha_h + beta_h) # Update gating variables pm = alpha_m/(alpha_m + beta_m) pn = alpha_n/(alpha_n+ beta_n) ph = alpha_h/(alpha_h + beta_h) mVec[v+1] = pm + (mVec[v] - pm)*np.exp(-dt/tau_m) nVec[v+1] = pn + (nVec[v] - pn)*np.exp(-dt/tau_n) hVec[v+1] = ph + (hVec[v] - ph)*np.exp(-dt/tau_h) # Update voltage denominator = gMaxL + gMaxK*(nVec[v]**4) + gMaxNa*(mVec[v]**3)*hVec[v] tauV = c / denominator Vinf = ((gMaxL)*EL + gMaxK*(nVec[v]**4)*EK + gMaxNa*(mVec[v]**3)*hVec[v]*ENa + Ivector[v])/ denominator voltageVector[v+1] = Vinf + (voltageVector[v]-Vinf)*np.exp(-dt/tauV) # Plot the results plt.figure(1, figsize=(10,10)) plt.subplot(4,1,1) plt.plot(timeVec,voltageVector) plt.title(&#39;Hodgkin and Huxley Simulation&#39;) plt.ylabel(&#39;Voltage in mV&#39;) plt.subplot(4,1,2) plt.plot(timeVec, mVec) plt.ylabel(&#39;g_Na activation variable m&#39;) plt.subplot(4,1,3) plt.plot(timeVec, hVec) plt.ylabel(&#39;g_Na inactivation variable h&#39;) plt.subplot(4,1,4) plt.plot(timeVec, nVec) plt.ylabel(&#39;g_K activation variable&#39;) Part 2 Unfortunately, there is no effective treatment to BTX poisoning. However, in theory, the membrane depolarization can be reversed using tetrodotoxin (TTX), which is produced by the pufferfish, blue ringed octopus, and other deadly creatures. This toxin also causes paralysis. However, unlike BTX, TTX prevents action potentials by binding to voltage-gated sodium channels and preventing the movement of sodium ions into the cell. Revise the above code to simulate exposure to TTX 300 ms after the BTX poisoning. Part 3 Observe the behavior of the neuron between 600 and 800 ms. While this looks like more ideal behavior than when the neuron was exposed to only BTX, what should the behavior of the neuron be if neither poison had been administered? (Note, while this is a conceptual question, feel free to alter the code to see what should occur). "],
["Ch5.html", "6 Firing Rates 6.1 Vocabulary 6.2 Introduction 6.3 Spike Trains 6.4 Spike Statistics 6.5 Summary 6.6 Exercises", " 6 Firing Rates 6.1 Vocabulary 6.2 Introduction 6.3 Spike Trains Figure 6.1: Example of a spike train. Graph A shows the recorded stimulus and graph B shows the recorded actions potentials during the stimulus. Assume that we measured a neuron firing in response to a sensory stimulus, and we recorded its voltage changes and displayed the signal in an oscilloscope. How should we analyze the information encoded in these action potentials? As we mentioned before, the action potential is an all-or-none event. This binary characteristic gives us a way to simplify the complicated voltage response curve: for every time point in our measurement, if there is a spike firing, denote its value as 1; if not, denote it as 0. After the recording, we get a sequence of 0s and 1s in a time-dependent order. We commonly refer to this sequence as a spike train, shown in Figure 1, part B. Since all action potentials fire to the same voltage level, there is no difference in their intensities. Thus, in order to have action potentials that convey meaningful information, neurons can only vary on timing of firing, including varying firing rates or varying the time intervals between each firing. Although this seems super-simplified, our spike train contains mostly the information we need to analyze if we want to know what causes the original neuron to fire. In order to systematically analyze these data in spike trains, we first need to define some statistics. 6.4 Spike Statistics Now we have a sequence of 0s and 1s which represent neural firing, the next step is to calculate the spike count rate, which is the number of spikes divided over a given time interval. This parameter directly shows the firing rate, but it cannot reflect variation. Assume that we have two neurons that have the same spike count rate. One is a regular-firing neuron and the spikes are evenly distributed along the time axis, while the other is a bursting neuron that fires sets of spikes with longer intervals between individual sets. How can we distinguish between these two spike trains? Here, we want to introduce another parameter called the interspike interval (ISI) or in other words, the time interval between every pair of spikes. In Figure 2, there is a histogram that shows the distribution of ISIs from an artificial spike train. The ISI histogram can be characterized by coefficient of variation (CV), which is the standard deviation of ISIs divided by the mean of it. Apart from that, we can also use the Fano factor to measure the spike variability. It is calculated by the variance of the number of spikes divided by the mean number of spikes in a given time interval. Compare to CV, Fano factor is less dependent on the intervals between spikes but more on the number of spikes in a given time bin. If the underlying firing rate varies or the spike firing in irregular time points, both CV and Fano factor increase. Thus, CV and Fano factors are useful secondary statistics that helps to measure variability in spike trains. Figure 6.2: Distribution of ISIs from a randomly firing artificial neuron. We can do a lot with a single spike train. However, in vivo, neural responses are highly variable and the response of a neuron to the same stimulus may even vary from trial to trial. Effectively, to account for the cross-trial variability, we need to analyze results from multiple trials to get a better estimate of the average neural response. A peristimulus time histogram (PSTH) can be generated by averaging across trials. The most direct method is to put trials in small time windows that correspond to each time point and calculate the spike count rate in window for each time point. By implementing this process, each time point is assigned an average rate, and by plotting we get a continuous frequency curve. One example is shown in the Exercise 1, in the “spike density” section, in which spikes are averaged in time windows, and then averaged across trials. In this case, all trials are run on the same neuron, which reduces the cross-trial variability and increases the time resolution. The response, however, may be affected by adaptation. Furthermore, we can also assess the firing pattern of a population of neurons by calculating the average spike counting rate for all the time points, and then averaging across trials. At this point, different trials are run on different neurons, and the generated response curve accounts for the response pattern of a population of neurons in the area that was tested. This method, while it generates better time resolution, omits the possible variability across neurons in the population. Choosing different time windows influences the characteristics of the frequency curve, as shown in Figure 3. In general, PSTH is essential because it transforms a discontinuous spike train into continuous response curves, which allows us to calculate the correlation between stimulus and response. This will be further elaborated upon in the later sections. Exercise 1: What are the pros and cons for each type of histogram? Figure 6.3: PSTH generated from different time windows. The size of the time window gets larger from top to bottom(0.005s, 0.025s, and 0.050s). While the smaller time window retains more information of the original spike train, the bigger time window gives a more smooth and continuous output. Figure 6.4: PSTH generated from different time windows. The size of the time window gets larger from top to bottom(0.005s, 0.025s, and 0.050s). While the smaller time window retains more information of the original spike train, the bigger time window gives a more smooth and continuous output. Sometimes, instead of collecting data from real neurons, we need to simulate spike trains from given statistics. The artificial spike trains can be compared with real data, or used to reconstruct possible firing patterns with a given stimulus. Here, we will discuss the homogeneous Poisson process, or the simplest way of generating artificial spike train. The homogeneous Poisson process entails that for every small interval on the timeline, the probability of an event happening (in our case, action potential) will be proportional to the length of the time interval, while the proportionality constant r is fixed. To understand this abstract definition, think about a timeline whereby at each time point, we throw a coin and record the head as 1. Try to visualize that timeline. We agree that all 1s will be randomly spread along the timeline, and the interval between when we get a pair of heads, varies along the timeline. This will look very similar to an artificial spike train generated by the Poisson process, whose distribution can be expressed by the following formula: \\[p(q\\ spikes\\ in\\ \\Delta{t}) = e^{-\\lambda}\\frac{\\lambda^{n}}{n!} \\] Figure 6.5: An artificial spike train generated by Poisson process and its ISI distribution. Notice that the spikes are randomly distributed along the time axis, and the ISI histogram has an exponential distribution. Worked Example: For this example, we will consider data collected by Robert Cat from a neuron located in an alien’s posterior inferior temporal cortex responding to a rapidly-changing color stimulus. Dr. Cat recorded the neuron at 1000 Hz for ten seconds and created a Boolean vector (spikes) where 1 signifies a spike. Create a program that calculates the neuron’s spike count rate, and then create a plot of the spike count rate versus time. # First, import the necessary libraries import numpy as np import matplotlib.pyplot as plt # Calculate the total number of spikes and store them in totalSpikes # Because the vector is binary, the sum of the 1s and 0s gives the total totalSpikes = np.sum(spikes) # Calculate the neuron’s spike count rate, and store it in spikeRate # We divide by 10 because we want our rate to be in the unit of spikes/second (Hz) spikeRate = totalSpikes / 10 # Print the spike count rate print(&#39;The spike count rate is: {} Hz&#39;.format(spikeRate)) Worked Example: Next, we will examine how to calculate the rate as an average across 50 trials of the same neuron Dr. Cat obtained responding to the same stimulus using the spike density rate. In this experiment, each trial was one second long, and measurements were taken at 1000 Hz. Dr. Cat noticed in their research that the neuron fired at an average of 50 Hz for the first 300 ms of the recording and an average of 15 Hz for the remaining 700 ms. First, simulate the neuron in Dr. Cat’s experiment and then, using this information, plot spike density rate versus time. # As usual, we&#39;ll begin by importing the necessary libraries import numpy as np import matplotlib.pyplot as plt # Define the two average spiking rates as probabilities p1 = 50/1000 # on average, 50 spikes in the 1000 time points p2 = 15/1000 # on average, 15 spikes in the 1000 time points # In order to create the data, we will create a matrix that # is numTrials by numTimePoints in size. We will initialize # it with zeros and then fill in the spikes later. dataMat = np.zeros((50, 1000)) # Here, we will create a nested loop. The outer loop will # loop through the 50 trials. The inner loop will loop through # the time points and use a random number generator to determine # the placement of each spike. # Data creation loop of 50 trials for j in range(50): # In each of the 50 trials, loop through 1000 time points for i in range(1000): # At each time point, we want the neuron to fire with # probability p1 in the first 300 ms, and probability p2 # for the remainder of the trial. # To do this, we will first create a conditional to determine # whether or not we are in the first 300 ms. If so, we will # use p1, and if not, we will use p2. if i &lt; 300: p = p1 else: p = p2 # At each time point, we flip a random coin using np.random.rand(). # This generates a random value between 0 and 1. If this value # is less than our target probability, the neuron will fire. if np.random.rand() &lt; p: dataMat[j, i] = 1 # Note that we do not need an &quot;else&quot; here because the rest of the # matrix is already 0. # Now that we have created our data, we can calculate the spike # density rate. # Sum all the trials to plot the total number of spikes in each # time bin, and store them in counts (HINT: we wish to sum over # all the rows, and numpy denotes rows before columns. This is # the reason we use axis=0 (i.e. the first axis)) counts = np.sum(dataMat, axis = 0) # Now, we need to translate these counts into a rate by dividing # by the number of trials and the dt density = (1/(1/1000)) * counts/50 # In order to create a plot, we need to create a vector of time # points to plot it against time = np.arange(1000) # Create spike density vs. time graph plt.figure() plt.plot(time, density) plt.xlabel(&#39;Time in ms&#39;) plt.ylabel(&#39;Spike density (Spikes per second)&#39;) The resulting plot looks like this: Figure 6.6: Spike density rate over 50 trials 6.5 Summary 6.6 Exercises 6.6.1 Conceptual Problems Define the spike count rate. What are the advantages and disadvantages of defining rate as a spike count? Define the spike density rate. What are the advantages and disadvantages of defining rate as a spike density? Define firing rates as population density. What are the advantages and disadvantages of defining rate as population activity? What are the qualifications for a Poisson spike train? 6.6.2 Coding Problems Part a. Create a Poisson spike train to simulate a neuron that fires for 2000 ms at an average rate of 50 Hz. The Poisson distribution is a useful concept to create random spike locations within a time frame (2000 ms in this case) that produce an average desired frequency (50 Hz in this case). The randomness can be achieved by using the np.random.rand() function, which generates a random value uniformly sampled between 0 and 1. If this random value is less than the specified probability of firing, than the code will generate a 1 indicating a spike. Otherwise, the spike train will contain zeros. Part b Using the following code template, add a counting variable to measure the number of spikes produced in the simulation. Use this total spike count to calculate the final spike count rate (spikes/second, or Hz) and see how it compares to the desired frequency of 50 Hz (50 spikes/second). # Import the necessary libraries import matplotlib.pyplot as plt import numpy as np # Initialize data structures # Hint: your simulation runs for 2000 ms timeVec = # Hint: you may express your desired rate as a nSpikes / 1000 ms probability probability = # Hint: you want the default value to be zero spikes = # Loop through each time point - fill in missing code for i in range(): if np.random.rand() &lt; probability: # fill in this key line # Compute the spike count rate here spikeCountRate = # Print the spike count rate print(&#39;The firing rate was: {} Hz&#39;.format(spikeCountRate)) # Create a figure of the spike train plt.figure() plt.plot(timeVec, spikes) plt.title(&#39;Spikes versus Time&#39;) plt.xlabel(&#39;Time (ms)&#39;) plt.ylabel(&#39;Spikes&#39;) Part c Using your spike train, compute a histogram of interspike intervals (ISIs). To do this, it will be helpful to find the locations of your spikes in your spike train. The function np.where() will do this (hint: you will only need the first value returned in the tuple). Hint: you will have 1 fewer ISI than number of spikes in your spike train. Part a Using the same Poisson process as above, simulate an experiment in which 40 trials of 2000 ms are created and place all trials into a single array. Fill in the code snippet below to create your array and plot a raster plot of all trials. # Import necessary libraries import numpy as np import matplotlib.pyplot as plt #fill in the time vector and the spike frequency value of 50 Hz timeVec = p1 = #Allocate space for the 40 trials x 2000 ms array allTrials = #Create a Poisson spike generator, that loops 40 times for all 40 trials for i in range(): # For each trial, use an inner loop to represent all 2000 time points for v in range(): # Create the raster plot for j in range(): # How many trials are we running? spikes, = #Fill in Spikes to represent every spike found # in the allTrials matrix. Index the jth trial # only. spikeTimes = timeVec[spikes] theseSpikes = np.ones(len(spikes))*j+1 plt.scatter(spikeTimes, theseSpikes, s=2, c=&#39;k&#39;) #Fill in the labels of the x, y axis plt.title() plt.xlabel() plt.ylabel() Part b Now compute the Fano factor for your spike array. This may be done in one line of code using the built-in functions for variance and mean from the numpy library. "],
["Ch6.html", "7 Reverse Correlation and Receptive Field Mapping 7.1 Vocabulary 7.2 Introduction 7.3 Spike-triggered Average 7.4 Reverse Correlation 7.5 Summary 7.6 Exercises", " 7 Reverse Correlation and Receptive Field Mapping 7.1 Vocabulary Poisson process Spike train Peri-stimulus time histogram Spike count rate Interspike interval Fano factor Coefficient of variation Spike-triggered average White noise Reverse correlation 7.2 Introduction Throughout our everyday lives, we receive an enormous amount of sensory inputs from our surrounding environment: the color of the clouds before sunset, the melody played by an old record player, the smell of apple pie, or the taste of your favorite dish. Our brain, with its incredible computational capacity, successfully encodes all these sensory inputs from different modalities to something we can perceive and understand, in the language of neurons. Our discussion from previous chapters noted that the language of neurons–or the neural code–consists of action potentials that are all-or-none events, and we learned how neurons fire an action potential. In this chapter, we are going to talk about why neuron fires and how to characterize and analyze these action potentials using spike trains. Based on this, we are going to discuss ways to study the relationship between outside stimuli and neural responses. 7.3 Spike-triggered Average An essential tool for describing neurons, and how they respond to certain stimuli, is the spike-triggered average (STA). The STA is the average value of the stimulus during some time interval before a spike occurs. Researchers record a neuron’s activity as it responds to various stimuli. First, the researchers must determine the amount of time before a spike they want to analyze. Once the data has been obtained and the time step determined, the value of the one-time step before a spike is recorded, and averaged across trials. This value ultimately characterizes the level of stimulus necessary for the neuron to fire. It is important to note that the spike-triggered average is measuring the average level of the stimulus, not of the neuron. This calculation is based on the probability of a neuron spiking due to stimuli activity to occur in the recent past. Figure 7.1: The spike triggered average can be used to calculate both the stimulus and the spike train. Figure 7.2: Example of a white noise stimulus using gray scale. The spike-triggered average can be utilized to determine the receptive fields of individual neurons. However, when using the STA to determine receptive fields, the stimulus presented to the recording neuron must be sufficiently random. If it isn’t, any correlation in stimuli will be presented in the generated receptive field, thus skewing the result. A white noise, is a type of stimulus with random variation where the value at each time point is independent of all other points. White noise can be employed in these instances to provide a receptive field without bias. White noise stimuli can look different based on the neuron and the system being observed, from a series of random auditory frequencies to randomly generated pixels stimulating the visual cortex. For each set of stimuli, the value at each time point does not correlate with the values around it. For more information on spike-triggered average analyses, especially concerning receptive fields,read this experiment. Worked Example: Paul the Python has been trying to figure out what every neuron in his reptilian brain responds to for purely scientific purposes. He has found a region in his visual cortex that responds to different hat sizes (in inches). He wants to find out which diameter of hat a particular neuron responds to (henceforth referred to as Paul’s neuron). To do so, he has decided to show his neuron many diameters of hats to try and find the spike triggered average but Paul the Python doesn’t have any arms so we have to help him out. Solution: First, generate random hat diameters that we will show Paul’s neuron. In this problem, we will show Paul’s neuron a new hat each millisecond for 3 seconds. import numpy as np # Import the necessary import matplotlib.pyplot as plt # libraries. Numpy is useful # for many things like generating # arrays and random numbers # Matplotlib will help with # plotting time = np.arange(0, 3, 0.001) # Create a time vector for 3 seconds # with a step size of 0.001 so # that each time step is one ms. # (This makes conversions easier # in the long run). We are # essentially showing Paul a new # hat diameter each ms. numbers = np.random.randn(len(time)) # Use np.random.randn() # to get a range of random # numbers that falls under the standard normal # distribution. The point of this step is just to get # a set of random values. This distribution will # typically yield values between -4 and 4. We are # showing Paul a new hat at every time point, so we # need to create a vector that is the same length as # the time vector. To do this, we could hard code 3000 # but it is better to write in len(time) in case we # decide to change aspects of the experiment in the # future. Remember, coding is about making life easy # for us in the future! diameters = abs(numbers) # Since we are using a normal distribution # and we can&#39;t have negative hat sizes, # we are taking the absolute value of # the random hat sizes. plt.figure() plt.plot(time, diameters) # Plot hat diameters against time to plt.xlabel(&#39;Time in s&#39;) # show what Paul is seeing in the 3 plt.ylabel(&#39;Hat diameters in inches&#39;) # second experiment. The resulting plot looks like this: Figure 7.3: Hat sizes shown to Paul the Python’s neuron. Now we have to model Paul’s neuron. Paul loves large floppy hats so this neuron is dedicated to detecting hats with large diameters. For this reason, his neuron will spike every time he sees a hat with a diameter over 2 inches. This neuron happens to spike 200 ms after he sees that particular stimulus. Paulsneuron = np.zeros(len(time)) # The neuron is usually at # rest. Because all we care # about in this example is if the neuron # is spiking, we can denote each spike as # a &quot;1&quot; and each non-spike as a &quot;0&quot;. This # is a placeholder for the neuron&#39;s # response, denoting that the default # value is rest. time = np.arange(0, 3, 0.001) # Same as above numbers = np.random.randn(len(time)) # Same as above diameters = abs(numbers) for i in range(len(time) -200): # This is a loop that will create if diameters[i] &gt; 2: # the spikes in Paul&#39;s neuron. Paulsneuron[i+199] = 1 # We are saying that if the value # of the current diameter is greater than 2, # Paul&#39;s neuron will spike (i.e show up as 1). # These values will be saved in the Paulsneuron # vector. Because neurons can&#39;t spike instantly, # we will delay the spike for 200 ms. This is why # we write [i+199]. As we are getting 200 fewer # values, we have to subtract 200 from the range # or else we would be trying to index by a negative # time value, and we would get an error. # Plotting time versus Paulsneuron in order to see the spike train plt.figure() plt.plot(time, Paulsneuron) plt.xlabel(&#39;Time in s&#39;) plt.ylabel(&#39;Model Neuron Response&#39;) The resulting plot looks like this: Figure 7.4: Simulated spikes from Paul’s neuron. Now we have our stimulus (hat diameters that Paul was exposed to) and our response (how his neuron responded to them). We can use this information to find the spike triggered average. spikes, = np.where(Paulsneuron == 1) # Find all the places where # Paul&#39;s neuron equals 1, # aka find where the spikes are. # The np.where() function returns a tuple. # Adding a comma after the variable name # tells Python to just return the first # value in the tuple. spikes = spikes[spikes &gt;= 300] # Filter out spikes earlier # than 300 ms. We decided above # that the neuron will spike 200 ms after the # stimulus. We arbitrarily choose a value greater # than that so that Python can show us a chunk of # time before the spike that includes when the # stimulus was shown to the neuron. To expand, # if we don&#39;t filter out spikes from the first # 300 ms, then if there is a spike at 100ms, # we can&#39;t find the stimulus at -200 ms because # the stimulus begins at time = 0. stimArray = np.zeros((len(spikes), 300)) # We want to pre-allocate # an array that will # eventually hold the stimulus from -300 ms before # to spike up till the spike. for i in range(len(spikes)): stimArray[i, :] = diameters[spikes[i] - 300 : spikes[i]] # We&#39;re isolating the stimulus from -300 ms before the spike up # till the spike and placing it into an array.The best way to # understand this is by starting in the brackets. We&#39;re saying # to take all of the stimuli 300 ms before the spike up till the # spike and then seeing which diameters they corresponded to. # This is saved in the array &quot;stimArray&quot;. print(&quot;The stimArray shape is&quot; , stimArray.shape) # Print the # shape of #stimArray to see its dimensions. STA = np.mean(stimArray, axis = 0) # This is where we actually # find the spike triggered # average. We&#39;re finding the # average stimulus that caused # the neuron to spike. time = np.arange(-300, 0, 1) # We want to see what the average # stimulus that caused the spike # looked like so we need to look # more than 200 ms before the spike. # Plot time versus the spike triggered average. plt.plot(time, STA) plt.xlabel(&quot;Time (ms before spike)&quot;) plt.ylabel(&quot;Average Stimulus Before Spike&quot;) The resulting figure looks like this: Figure 7.5: Spike-triggered average of Paul’s neuron. Therefore, the average stimulus that causes Paul’s neuron to spike is a hat with a diameter of about 2.5 because we are selecting hats greater than 2 inches to be the stimuli that drive Paul’s neuron. Python found this for us. You can see that the stimulus shows up on the graph about 200 ms before the neural response because this was how we created the simulated neuron. Worked Example: Now that Paul knows the average stimulus that causes his neuron to fire, he wants to create a linear model of his neuron. Use the linear model to help Paul approximate the neuron’s firing rate. Solution: Thankfully, we can use the spike triggered average that we found in the previous problem to approximate the firing rate. This is because the spike triggered average is like a template that we use to compare with the stimulus. To do this, Paul decides to use convolution. At first this seems difficult and could potentially require a lot of code. However, numpy built-in functions are our friend here, specifically the function np.convolve(). There are two variations of convolution that we can ask Python to do. One variation is called ‘same’ and the other is called ‘valid’. We will explore both arguments. By convention, when we convolve two vectors, we call the smaller of the two the kernel and the larger one the signal. Let’s begin by printing the shapes of the STA and the stimulus to see which will be the signal. print(diameters.shape) # reads: (3000,) print(STA.shape) # reads: (300,) Now that we know that STA is the smaller vector, we call it the kernel and our stimulus, “diameters”, is the larger vector so it is the signal. We’ll begin by exploring convolution with the ‘same’ argument. Use the format “variablename = np.convolve(signal, kernel, ‘same’)” import numpy as np # Import numpy library import matplotlib.pyplot as plt # Import matplotlib for plots # Perform the convolution predictedfiringrate = np.convolve(diameters, STA, &#39;same&#39;) print(predictedfiringrate.shape) # print the shape so we can # compare to the &#39;valid&#39; # argument later. # Note: the output is (3000,) plt.figure() plt.plot(predictedfiringrates) plt.title(&#39;Same Argument&#39;) The resulting figure looks like this: Figure 7.6: Convolution with ‘same’ argument. We can repeat the process, this time using the ‘valid’ argument instead of ‘same’. predictedfiringrate = np.convolve(diameters, STA, &#39;valid&#39;) print(predictedfiringrate.shape) # prints: (2701,) plt.figure() plt.plot(predictedfiringrate plt.title(&#39;Valid Argument)) The resulting figure looks like this: Figure 7.7: Convolution with ‘valid’ argument. There are a few things to consider here. The most obvious is the shape of the graphs. By looking at the graphs, you can see that the ‘same’ and ‘valid’ plots are essentially the same but ‘same’ has extra values at the edges. The ‘same’ argument caused the shape of the variable ‘predictedfiringrate’ to equal 3000 while the ‘valid’ argument caused the shape of ‘predictedfiringrate’ to equal 2701. 2701 is the size of the difference between the signal and kernel ((3000-300) + 1 = 2701). The ‘same’ argument compares the signal and kernel even when the kernel isn’t completely lined up with the signal. A visual comparison is shown in the figure below. Figure 7.8: Difference between ‘same’ and ‘valid’ arguments. The figure visualizes this concept using Paul and his friend, Cody the Cobra. Paul is enjoying the sunshine and is stationary. His friend Cody the cobra is smaller in length and is slithering past Paul. Paul represents the signal and Cody represents the kernel. Convolution using the ‘same’ argument starts when Cody first begins to overlap with Paul (a). In this instance, the comparison will look at one value of the kernel and one value of the signal. As Cody continues, more parts of him overlap with Paul (b). In terms of convolution, this is like when we move the kernel over one spot and we compare the two values of the kernel to two values of the signal. Then we move the kernel by one more spot and compare three values, and so on. This is reflected in the ‘same’ graph when we see a steep increase in the beginning.This is because zeros are being averaged into the signal for all the points of the kernel and signal that are not overlapping. So with every increasing overlapped point, the graph also shows an increase. As Cody slithers past Paul, there are moments when they are completely overlapping (c and d). The ‘valid’ argument only describes these moments. For this reason, we don’t get the steep edges in the ‘valid’ graph that we do in the ‘same’ graph. As Cody continues to slither past Paul, there will be moments when they don’t completely overlap (e and f). These moments are reflected as the decrease in the ‘same’ graph because the amount of values of the kernel and signal being compared decrease and zeros get averaged into the signal. Great! Now we have both a linear model and convolving the STA with the stimulus essentially provides the predicted firing rate. This is because when the stimulus and spike triggered average are similar, the convolved value is higher, suggesting that the neuron is firing. Likewise, when the stimulus and the spike are dissimilar, the convolved value is smaller, suggesting the neuron isn’t firing. Now we have a prediction of what Paul’s neuron should do after being shown many hats of different diameters. 7.4 Reverse Correlation Figure 7.9: Reverse correlation encompasses both spike triggered averages and spike triggered covariance. When analyzing neurons and neuronal responses, there are two main factors: the inputs (controlled by researchers), and the outputs (measured by researchers). The process of reverse correlation implements the analysis of outputs to determine the inputs that the neuron will respond to with a spike. The spike-triggered average is an application of this process as it looks back at the stimuli preceding a spike to determine information about the sensitivity and response of the neuron. In addition to spike-triggered average, a calculation known as spike-triggered covariance can be used to analyze neuronal responses. Spike-triggered covariance (STC) can be used to identify multi-dimensional inputs to a neuron and is especially useful in linear-nonlinear Poisson models that will be discussed later in this section. STC uses the covariance, variability between two factors, of stimuli that trigger spikes in a neuron to determine a neuron’s response characteristics to multi-dimensional stimuli. The basic model for reverse correlation is a Linear Single Input Single Output system (LSISOS). Such linear systems assume the two principles of homogeneity. First, the neuron will not undergo processes such as habituation and will always respond in the same way to the stimulus. Second, superposition: the response from multiple stimuli will be equal to the sum of the individual stimuli. In this model, the LSISOS response is the sum of the spikes scaled to time. Similar to spike-triggered averages, it is best to input a white noise stimulus and then cross-correlate it with its output, which will give you the spike-triggered average. In cross-correlation, the higher the similarity between the two values (the stimulus value and the output value), the greater the correlation value (the spike-triggered average). The LSISOS model assumes a linear activity of neurons that is not entirely accurate due to neuron characteristics such as a spike threshold and a refractory period. A new model, known as the linear-nonlinear-Poisson model takes these factors into account. There are three stages to this model: linear stage, nonlinear stage, and the Poisson spike generator stage. The linear stage considers how a neuron responds to a specific feature in a spatio-temporal linear sense. The second stage takes the linear output and input through a nonlinear function to give a neuron’s instantaneous spike rate. The nonlinear function can either be a logistic curve or a rectified linear (ReLU) function. The final step translates the output of the initial steps into spikes using an inhomogeneous Poisson process. The final result from the Poisson generator demonstrates the areas of the stimulus where a spike is more likely to occur. Reverse correlation is a technique used for understanding what neurons are responding to, and the spike-triggered averages discussed earlier are one example of how reverse correlation is implemented. Figure 7.10: Spike-triggered covariance shows how two different stimulus dimensions can be calculated together. 7.5 Summary Reverse correlation and all the concepts that play a role in this widely implemented technique, from different modes of spike statistics to various types of stimuli, can be an intimidating topic in computational neuroscience. Analyzing the relationship between inputs and outputs to understand the effect each has on the activity of a neuron is the root of this topic. These analyses can move in both directions: input to output, or output to input. One can manipulate the stimulus and measure the resulting spike train through various statistical methods, or one could use reverse correlation by utilizing the known output of a spike to look back and understand the input necessary to create such a response. These analyses are working on grasping what stimuli the neuron does, or does not, “like”. In other words, they help us predict the neuron’s responses. 7.6 Exercises 7.6.1 Conceptual Exercises Spike-triggered average (STA) is the average of the stimuli that preceded a spike. Describe an experimental design that would allow you to compute an STA. Above is a graph of the convolution of the stimulus intensity (horizontal speed of moving dots) and the STA obtained from the data of a fly’s H1 neuronal response to visual motion during the first 1000 time points. Convolving the spike train and STA is often used to reconstruct the firing rate. From the graph, compare the results of the convolution at point A and point B. How does the intensity of stimulus at each given time inform us of the neuron’s behavior? White noise like Gaussian white noise is often presented as the stimulus when conducting experiments to characterize the receptive field of a neuron. Provide an example of a white noise stimulus for the neurons in one of the sensory systems. What is the importance of this technique? How is adaptation minimized in a reverse correlation experiment? The STA functions as a linear filter to predict the neuronal response to a particular type of stimulus. This linear filtering step is often followed by a nonlinear process that is applied to our filtered stimulus in the linear-nonlinear Poisson (LNP) model. Why is this step important? In other words, what are the shortcomings of only having a linear process? 7.6.2 Coding Exercises Exercise 3 (Challenge!) Match each concept to the Python function. Concepts: Fano Factor Spike Count Rate Interspike Interval # Function 1 prob = 45/1000 spikeMatrix = np.zeros((1000,1000)) for i in range(1000): for j in range(1000): if np.random.rand() &lt; prob: spikeMatrix[i,j] = 1 spikeCountRates = np.sum(spikeMatrix, 1) plt.figure(figsize=(8,8)) plt.subplot(2,1,1) plt.hist(spikeCountRates, 40, edgecolor=&#39;black&#39;) plt.xlabel(&quot;Average firing rate (Hz)&quot;) plt.ylabel(&quot;Frequency&quot;) # Function 2 np.var(spikeCountRates) / np.mean(spikeCountRates) # Function 3 spikeCountRates = np.sum(spikeMatrix, 1) totalSpikes = int(np.sum(spikeMatrix, axis=None)) isi = np.zeros(totalSpikes - 1) count = -1 for i in range(1000): spikes = np.nonzero(spikeMatrix[i,:])[0] for j in range(len(spikes)-1): count += 1 isi[count] = spikes[j+1] - spikes[j] plt.subplot(2,1,2) plt.hist(isi, 100) plt.xlabel(&quot;ISI (ms)&quot;) plt.ylabel(&quot;Frequency&quot;) "],
["Ch7.html", "8 Decoding 8.1 Vocabulary 8.2 Introduction 8.3 Imaging Techniques 8.4 Introduction to Decoding 8.5 What is a classifier? 8.6 Cross validation 8.7 Conclusion", " 8 Decoding 8.1 Vocabulary Imaging techniques EEG MEG fMRI ECOG Multivariate Pattern Analysis (MVPA) Decoding Classifier Correlation classifier Distance-based classifier Boundary-based classifier Curse of dimensionality Linear discriminant analysis Linear support vector machine (LSVM) Cross-validation Rank measure 8.2 Introduction In our previous chapter on reverse correlation, we discussed how we may utilize spike trains to look back and understand the input necessary to create such a response in a neuron. We discussed the ability to not only correlate an output with a specific stimulus but additionally the capability to decode raw brain data measured via EEG, MEG, fMRI, and ECOG. In other words, for some given neuronal signals, what stimulus was provided to that neuron which caused it to fire? In this chapter, we will introduce several methods of neural decoding. In particular, we will detail the specifics of several classifiers pertinent to decoding, as well as their various benefits and constraints. 8.3 Imaging Techniques For decoding problems, there are numerous different types of data that could be analyzed. The simplest recording of a single neuron will give a spike train that contains 0s and 1s, or we can average the rate across time bins to generate a continuous curve to study. Although it might be easier to just focus on one neuron, usually data are drawn from a population of neurons. In some cases, a pseudo population of data is constructed from a single-neuron recording in order to reduce noise or assess group activity. As a type of supervised learning, in decoding problems, both the input and output are given, but this input can vary in its appearance. There are multiple types of imaging techniques commonly employed by researchers to obtain data and recordings from participants. We will discuss four of the main techniques here: EEG, MEG, fMRI, and ECOG. 8.3.1 EEG Figure 8.1: Raw output of EEG recording Electroencephalography (EEG) is a method by which the electrical signals produced by action potentials across a large population of neurons are recorded to distinguish areas of activation in the brain. In an EEG setup, electrodes are placed around the scalp in a non-invasive manner to record voltage fluctuations. EEGs often record such fluctuation every millisecond, allowing for strong temporal resolution. However, since the electrodes are placed on the outside of the scalp there is difficulty with the spatial resolution of the recording. The actual output will be a sequence of voltage values over time from each electrode. This output can be decoded with multivariate pattern analysis (MVPA) where all the relationships between time points can be factored in the analysis. MVPA is able to be utilized for all the imaging techniques discussed in this chapter as a broad form of decoding that factors in the relationship between variables so they are not treated as independent variables. Overall, EEG is a cheap, non-invasive imaging method that is implemented in many laboratories. 8.3.2 MEG Figure 8.2: Image of a participant in a MEG scanner. Magnetoencephalography (MEG) is a brain recording technique similar to EEG. MEG measures the small magnetic fields produced by a population of neurons being activated together, demonstrating areas of the brain that are being highly stimulated. For a MEG scan, the machine encompasses the exterior of the participant’s head and must be completed in a magnetically shielded room as the magnetic fields produced by the brain are quite small. Similar to EEG, the output will be a time-series data that is conducive to strong temporal resolution as data is being recorded every millisecond. In this case, instead of voltage over time as in EEG, MEG will give a recording of magnetic flux over time. Since the machine is recording from outside the skull the spatial resolution and only providing data on the activation at each location the spatial resolution is weaker. MEG is more expensive than EEG but provides similar, temporally accurate, data on the activation of regions of the brain. 8.3.3 fMRI Figure 8.3: Image of an fMRI scan with red sections indicating areas of the brain that are more active than the control condition. Functional magnetic resonance imaging (fMRI) is a system that shows where oxygenated blood is focused in the brain, indicating which regions of the brain are most active. Oxygenated and deoxygenated blood have different magnetic properties allowing researchers to differentiate the two in an MRI scanner. Participants are placed in a machine that encompasses their head for the procedure to take place. fMRI scans, while external, are still able to achieve strong spatial resolution through the use of voxels. Voxels are small three dimensional sections that the brain is divided up into, and the color assigned to each voxel represents its level of activation as compared to a standard baseline. All voxels are active the majority of the time, so the output of the scan is focused on which voxels are more activated during a specific task of interest compared to this control activation. The product of an fMRI scan is an image of the participant’s brain with regions of higher relative activation indicated with color. These colored regions indicate the presence of more oxygenated blood, as greater activation requires more oxygenated blood to sustain it. Despite its successes in spatial resolution, fMRI scans have poor temporal resolution as they take six to ten seconds for blood-oxygen-level-dependent (BOLD) contrast to show changes after something happens. fMRI provides descriptive, easily interpretable imaging, but requires expensive machinery with poor temporal resolution. 8.3.4 ECOG Figure 8.4: Image depicting electrodes placed on cortex for ECOG imaging. Electrocorticography (ECOG) is a brain imaging technique that is not utilized often as it requires electrodes to be placed on the exposed surface of the cortex of a participant’s brain. The electrodes record electrical activity in the brain, similar to EEG. However, due to the proximal location of the electrodes, ECOG is able to record with both extremely accurate spatial and temporal resolution. ECOG introduces questions regarding ethics and treatment on humans as it requires exposing the surface of the brain. Therefore, ECOG is typically only implemented on participants with epilepsy who require the placement of electrodes on their brain to record from the region where their seizures are centralized. Due to its similarity to EEG, the ECOG output would also be tracking voltage over time from each electrode. ECOG is able to provide critical data but is a difficult and extreme procedure. Features Exercise: What features can be used in decoding different types of data? Fill in the chart below with corresponding features for each type of data. The first one has been done for you. Data Type Features Single neurons Firing rates, spike counts Population of neurons ? EEG signals ? fMRI ? 8.4 Introduction to Decoding With all these data from the various brain imaging techniques in hand, we want to decode the data–in other words, we want to detect the activity pattern buried in the random, noisy neural firing data and analyze if different stimuli lead to different activity patterns. If by analyzing activity patterns we can “predict” the stimulus that causes the activation and if the accuracy of “prediction” is higher than just random guessing, we can say that we successfully decoded the information in our brain activity recording. The word “prediction” is in quotation marks because we are not foretelling future events, but instead checking the answer key to see if our solution is correct. Depending on the imaging techniques we used in the data acquisition phase, there are multiple ways to present and analyze data. Popular brain imaging techniques like EEG, MEG, fMRI, and ECOG all give recordings for a population of neurons, and it is the experimenter’s choice to focus more on the group level or on local variance. It might be the case that whole-brain EEG data was implemented to analyze event-related brain activation, or it could be that occipital and frontal electrodes were selected to measure their correlation. Another example comes from the field of fMRI, where current interests shifted from the classical approach that explores the involvement of brain regions in certain activities to revealing the representational pattern within functional regions. Depending on the purpose of the study, different classifiers can be selected to categorize the data. Classifiers are algorithms that make predictions for test data based on a “learned” pattern from the training set. Here are some types of classifiers generally used in decoding. 8.5 What is a classifier? In order to decode brain data, we will need a classifier, which allows us to learn from labeled data and make predictions on test data from its experience with the labeled data. We will discuss three types of classifiers which each have their own strengths and weaknesses. Note that all of the classifiers we will talk about fall under the category of supervised learning, as they all make decisions based on labeled training data. 8.5.1 Correlation classifiers The first classifier we will examine is the simple, yet powerful correlation classifier, which works well for multivariate classifications. In a correlation classifier, the mean of each class is observed and correlated with each input feature. The class most correlated with the test item is the classifier’s predicted output. James Haxby does a great job explaining some of the more intricate details to be aware of when implementing a correlation classifier. In practice, we consider each neuron individually as a test point and split the rest into training data. Next, we find all of the training trials for each class and calculate its respective mean. We then find the correlation coefficients between the training data and our test point and assign our predicted class to be the category with the highest correlation. We can then determine the accuracy of this classifier by evaluating the percentage of correctly classified test points. 8.5.2 Distance-based classifiers The second classifier we will discuss is the distance-based classifier, which bases its decision making on the distance calculated from the test point to the training point. One popular example of a distance-based classifier is the k-nearest neighbors (KNN) algorithm, where k is the number of training points that are closest to our test point. Each training point yields one vote to decide the class for each test point. The class with the most votes is then the resulting classification of that test point. Note that k is conventionally odd to ensure a majority class. To perform the algorithm, we first sample each of our training points. For each of these points, we calculate the distance to the test point. These distances are then sorted to ensure picking the k-smallest distances i.e. nearest neighbors. Finally, we take the most frequent class to be the predicted class of our test point. Before we move on to our next classifier, we must touch on one of the major pitfalls of distance-based classifiers: the curse of dimensionality. Distance-based algorithms work great in low dimensions where it is computationally inexpensive to calculate distances. The curse of dimensionality pertains to the fact that, as we move up in dimensions, the distances between all points to one another grow very large and the variability among distances becomes small. Therefore, your data must grow exponentially as dimensions are increased in order to sample enough of the space for these dimensions to be meaningful. It is for this reason that when working with high dimensional data, a distance-based classifier may not be the best choice. 8.5.3 Boundary-based classifiers The last of the three primary classifiers we will discuss are boundary-based classifiers, which produce some line or curve separating classes in two dimensions, a 2D plane to separate classes in three dimensions, or an abstract boundary (hyperplane) in higher dimensions. One example of a decision-based classifier is the Linear Support Vector Machine, which functions similarly to Linear Discriminant Analysis. Linear Discriminant Analysis works by asking what is the best line/hyperplane we can draw to separate the centroid means of our classes, whereas a Linear Support Vector Machine (LSVM) instead draws a boundary between the hard examples in the training set. We mentioned that distance-based classifiers are not a good choice of a classifier for higher-dimensional data. Conversely, LSVMs work well with high dimensional data; instead of calculating large distances between points, we only require a single hyperplane separating classes. Data points falling on either side of the hyperplane can be used to predict test point classes. In an LSVM algorithm, we aim to maximize the margin between the training points and the hyperplane via a cost function. Similarly to our neural network weight updating, when our LSVM misclassifies a data point, the weights determining our hyperplane are adjusted by this cost function. One question you may be asking yourself based on the last chapter, “Wait–what about neural networks? We just learned that they can make decisions based on labeled input data!” This is a natural question to ask and the answer is in fact, yes–neural networks can function as a classification algorithm. However, when creating a classifier, the setup of a neural network is a significant hassle in terms of parameter tuning (layer size, layer count, learning rate, etc). When possible, it makes more sense to work with one of the previously discussed trivial classifiers, which are more lightweight than a neural network and work “out of the box.” 8.6 Cross validation We talked about that decoding means to make predictions on the test set based on the pattern from the training set. It is worth mentioning that both the test set and the training set, although all from experimental data, should be clearly separated during learning and predicting. Otherwise, you will fall into the circular logical fallacy. Formally this is done by cross-validation, a scheme that partitions the data set into the test set and the remaining data into the training set, and then predictions can be made on the test set. The training and predicting processes repeat several times to obtain a prediction for every data point. This may sound paradoxical since we mentioned that it is problematic to use A to predict A, but here since the test and training sets are clearly separated for every round of prediction, and the predicted results are never used for training, we are not falling into this logical trap. Cross-validation is a decoding strategy that includes some subtypes like leave-one-out cross-validation, which is an extreme case in the cross-validation family. This method leaves exactly one sample to be the testing set and uses all other samples as the training set. It is worth noticing that when data are classified into multiple groups, one sample must be left out for every group. This is to prevent unbalancing in the training set, as an unbalanced training set may lead to a biased model. This method, while having the best chance to generalize to new examples, also requires very high computational power. A less demanding method is the k-fold cross-validation where k splits are made and (k-1) groups are assigned to the training set. The remaining group serves as the test set. The training and predicting repeats k times, and it is generally faster than leave-one-out-cross-validation in terms of computing power. The effectiveness of the classifier is evaluated by accuracy, which is usually computed as the average correctness across all samples. Lastly, another method is the rank measure, which ranks the probability for all labels and measures the distance between the predicted label and the top. Sometimes it is worth noticing that higher accuracy does not mean better classification. Assume that based on some brain data we want to classify patients into two groups: “children who have ADHD” and “children who do not have ADHD”. It is better to misclassify children without ADHD into the ADHD group, compared to classifying children with ADHD to the control group, as the latter one may be more deleterious. Figure 8.5: The Logical Flow of Cross Validation. Notice that the loop continues until every group of data served as the test group. Case study exercise: A group of researchers is studying object recognition in the inferior temporal cortex using ECOG and decoding. The neurons are not all equally responsive because an electrode array was not making full contact with the participant. What issues might this cause in decoding data? Discuss how you might fix this problem. 8.7 Conclusion When performing neural decoding, we are aiming to determine what information about the stimulus is available in the electrical activity of neurons. There are many areas in which decoding can be applied and used to make predictions about what people are thinking, dreaming, seeing, or hearing. In the fast-moving field of Computational Neuroscience, we will likely see great strides made in decoding in all of these areas. It is paramount to our interests as Neuroscientists to be mindful of certain ethical questions as this progress is made. In China, we already see the persecution of both the Uyghur and Hong Kong populations through government-sponsored facial recognition. This abuse of facial recognition technology is a strong indicator that these decoding techniques may similarly be used in the future by malevolent actors. One potential dystopian scenario based on these methods might include crime prediction and imprisonment solely based on brain activity. It is our responsibility to be mindful of how this technology is introduced to the field, as well as the world. Ethics exercise: Some say that decoding could allow scientists to “read minds”. Here is one article that refers to decoding as “mind-reading”. In light of this, what might be some ethical issues regarding the various applications of decoding? How could we potentially protect against these issues? Coding exercise: The code below codes for two separate clusters of data with means at 0.05 (blue) and 0.95 (red) which is plotted in a scatter plot. import numpy as np import matplotlib.pyplot as plt np.random.seed(10) m1 = np.array([0.05, 0.05]) m2 = np.array([0.95, 0.95]) sigma = np.eye(2) data1 = np.random.multivariate_normal(m1, sigma, 100) data2 = np.random.multivariate_normal(m2, sigma, 100) plt.figure() plt.scatter(data1[:,0], data1[:,1], c=&#39;blue&#39;) plt.scatter(data2[:,0], data2[:,1], c=&#39;red&#39;) Based on this scatter plot and the code above, fill in the following code. The code should generate a test point from either group m1 (the blue scatter plot) or m2 (the red scatter plot). Then the distance between the generated test points and the two means should be found using the pdist() function. You can look up the pdist() function to learn more about it and its arguments. This should be done in a for loop with 100 steps. The code additionally computes the accuracy of the decoding. This part is mostly written for you but remember to initialize the data structure and write the conditional to help determine accuracy. # Importing pdist function from scipy.spatial.distance import pdist # Initiate data structure for accuracy accuracy = np.zeros( ) mat1 = np.zeros( ) mat2 = np.zeros( ) # Loop to classify which group the test point is in for i in range( ): # Conditional to randomly pick a point from m1 or m2 if np.random.rand() : myMean = realClass = else: myMean = realClass = # Define test point myPoint = np.random.multivariate_normal( , , ) # Calculate the distance to m1 and m2 (row 0: myPoint; row 1: m1 or m2) mat1[0,:] = mat1[1,:] = mat2[0,:] = mat2[1,:] = dist1 = pdist( ) dist2 = pdist( ) # Conditional to assign predicted class to be the class w/ smallest distance if dist1 dist2: else: # Conditional to determine trial accuracy if : accuracy[i] = 1 # Calculate mean accuracy meanAcc = np.sum(accuracy)/100 print(meanAcc) "],
["Ch8.html", "9 Neural Networks 9.1 Vocabulary List: 9.2 Introduction/Background 9.3 Different Types of Learning 9.4 McCulloch-Pitt (MCP) Neurons 9.5 Perceptron 9.6 Summary", " 9 Neural Networks 9.1 Vocabulary List: Neural network Supervised Learning Unsupervised Learning Reinforcement Learning McCulloch-Pitt (MCP) neuron Perceptron Step function Linearly separable Activation function Sigmoid activation function Hidden layers Back propagation Cost 9.2 Introduction/Background Imagine for a moment that you wake up, groggy and not looking forward to your commute, when you ecstatically remember that you don’t have just any car, you have a self-driving car. You slide into the driver’s seat of your Tesla and faintly pay attention as your car does the heavy lifting and drives you to work. When one considers the concept of a neural network, a biological definition may first come to mind in the sense of the neuronal connections in the brain; however, this chapter delves into how we can recreate the learning apparent in our biology through computational models. Although this may sound like a slightly intimidating goal, neural networks have become a commonly used method. They are found in a wide variety of technologies from Tesla’s self-driving cars to Go playing robots. Overall, the goal of a neural network is to identify existing patterns in stimuli or inputs and produce an output that would mirror the output of our own brain through a set of determined algorithms. This allows us to create complex neural networks that can allow algorithms with the ability to learn. In this chapter, we aren’t going to delve into the deep complexities of neural networks required to fully understand how a self-driving car works, but we will outline the basics of how machines learn through neural networks. Neural networks identify existing patterns in stimuli. This means that based on a series of inputs, a neural network identifies whether or not the input conforms to a specific group or definition. In other words: a computer learns to perform a particular task by analyzing sets of examples. Take for example a technology that recognizes whether or not there is a face in a photograph. The neural network may ask if a stimulus has eyes, a nose, and a mouth. If the answer is yes, it will recognize the input as a face. If the stimulus lacks these features, the model will give an output to convey that there is no face. The output in this situation is the binary answer of whether or not a face exists. The more questions asked and the more layers in the neural network, the more complex stimuli and patterns we can look for. The initial example given here is a highly simplified idea of a neural network. In this chapter, we will start with the most simple building block of a neural network and build up to a more complex network. 9.3 Different Types of Learning Before defining a neural network, first, let’s take a moment to consider the concept of learning. Learning is something that can be defined in a variety of ways. One definition is the acquisition or modification of knowledge, behavior, skills, values, or preferences. What does this mean in the context of deep learning and neural networks? It may be difficult to use just one definition of learning to understand neural networks, so instead let’s consider three different types of learning: supervised, unsupervised, and reinforcement learning. Supervised learning is where a teacher provides input and the expected outputs to a student for the student to better predict future problems. This is a system of learning which you may be familiar with, one example is when a teacher gives you both the problem and the answer for you to be able to do future problems. Another example is computer vision learning. Giving a computer examples of different visual stimuli, such as handwriting, it can learn to distinguish between different letters using a neural network. Unsupervised learning is learning that occurs in the absence of a teacher. A student simply looks at patterns and tries to maximize correlations or find a basic understanding. Hebbian learning is an example of unsupervised learning. Finally, reinforcement learning is the shaping of behavior through reward and punishment. It is learning shaped through interactions with the environment. An example of this would be the robot AlphaGo which was taught how to beat humans at the game of Go. The neural networks we will be discussing in this chapter primarily use supervised or unsupervised deep learning, but if you are interested in reinforcement learning, this video on AlphaGo is a great resource. As you continue to read through this chapter, keep the goal of neural networks in mind as well as the various types of learning which can be used to achieve this goal. Exercise 1: Briefly describe the different kinds of learning. Can you provide a real-world example for each? (one not mentioned in the reading.) Exercise 2: Are certain kinds of learning more capable of tackling complex issues, why or why not? What kind of questions can be addressed by individual kinds of learning? 9.4 McCulloch-Pitt (MCP) Neurons MCP neurons were some of the first examples of artificial neurons that can be used to build networks. MCP neurons are named after Warren McCullough and Walter Pitts, who together proposed the model in 1943. Pitts self-taught logic and mathematics. He eventually ended up doing research at the University of Chicago, despite adverse conditions growing up. When he met Warren McCullough, a professor at the university, McCullough suggested that Pitts come to live with him and the two began a research partnership through which they produced their concept of the MCP neuron. The MCP neuron is a simple analog of its biological counterpart. The neuron receives one or multiple inputs which are then summed up to produce an output. These summed inputs essentially tell the neuron whether or not to fire. It is, however, slightly more complicated than a yes or no question as to whether the neuron fires. Each input is multiplied by an assigned weight. These resulting values are then added up. The model then compares the actual summation to an already existing threshold value. If the sum of the various inputs multiplied by the weights is greater than the threshold, the neuron is considered to be firing. If the sum is less than the threshold, the neuron does not fire. The equation is shown below: \\[Output = 1 \\ if\\ \\sum x_{i} w_{i} &lt; threshold \\] \\[Output = 0 \\ if\\ \\sum x_{i} w_{i} \\geq threshold \\] Exercise 3: How does an MCP neuron work? How similar is it to a real-life neuron? Exercise 4: Before we delve into further details about neural networks, what do you think could be some of the potential limitations of MCP neurons? MCP neurons function as effective and simple building blocks but they do have certain limitations. Let’s consider a neural network designed to recognize a human face again. MCP neurons can ask certain types of questions to answer the question of whether or not something has a human face, such as: Does this stimulus have eyes and a mouth? Does this stimulus have eyes or a mouth? Does this stimulus not have fur covering the entirety of its skin? These AND, OR, and NOT questions can be answered in a binary (yes or no) manner and thus can be modeled by an MCP neuron. MCP neurons cannot, however, answer what are called exclusionary, also known as XOR questions. Let’s consider the example of a neural network that suggests movies. You have two hours to watch a movie and cannot decide between a romance or horror film. You can’t watch both due to your time constraints so you need a neural network that will suggest either a romance movie or a horror movie but not both movies. This is an example of a situation in which asking an XOR question is necessary. In this case the question specifically is: Romance Horror Possible Picks? 1 1 0 1 0 1 0 1 1 0 0 0 The MCP neuron lacks the ability to ask an XOR question due to the nonlinear nature of its question. Earlier it was mentioned in this chapter that MCP neurons are based upon binary inputs and outputs. In the case of the XOR question, the complexity of the input-output relationships, due to the nonlinearity apparent in the question, prevents the neural networks from being able to produce an answer. Despite this drawback, there are ways to produce more complex neural networks which we will elaborate on later in this chapter. Coding exercise: Fill in the input and output for an AND gate in the following code, implement it in a Jupyter Notebook. # Import useful packages import numpy as np import matplotlib.pyplot as plt # Define Output and Input X1 = np.array([ [ , ], [ , ],[ , ],[ , ] ]) Y1 = np.array([ [], [], [], [] ]) 9.5 Perceptron Before we dive into neural networks and discuss how they work and what they do, we will introduce the concept of a perceptron and discuss its relevance. A perceptron is an algorithm for performing binary classification based on a step function. A trivial perceptron functions as follows: Consider a set of inputs and a corresponding set of weights: \\[Output = f(x) = \\begin{cases} 1, &amp; \\text{if $\\sum w_{i} x_{i} + b \\geq 0$}\\\\ 0, &amp; \\text{if $\\sum w_{i} x_{i} + b &lt; 0 $} \\end{cases}\\] Take the dot product of these two sets. Add another predetermined number called bias. If the result is greater than or equal to 0, the output is 1; otherwise, the output is 0. This is the step function: \\[Output = f(x) = \\begin{cases} 1, &amp; \\text{if $\\sum w_{i} x_{i} \\geq threshold$}\\\\ 0, &amp; \\text{if $\\sum w_{i} x_{i} &lt; threshold $} \\end{cases}\\] Note that in this step function , we compare the result of part 3 to 0. Alternatively, we can subtract b from both sides so that -b is a threshold value to compare with instead of adding bias and comparing to 0. Figure 9.1: Scheme of a single-layer perceptron. Inputs are multiplied with their corresponding weight and the products are summed up plus the bias. The result is then entered in the activation function, which generates the output. Code Exercise (continued): Assume that bias equals to -1. Define the initial weights randomly by sampling from a uniform distribution between -1 and 1. Use the code below to get started. # Initialize parameters # eta is the learning rate for your model eta = 0.01 output = np.zeros(4) bias = weights = # Initialize data structure to hold the accuracy of your model&#39;s prediction accuracy = np.zeros(500) Follow the summation and bias function above in Figure 1, fill in the blanks inside the for loop: # Calculate the output for the summation and bias function output = + np.matmul( , ) # Input the output in the activation function, # the result will be the prediction of this model based on the # given inputs. output = # Denote the prediction as yHat yHat = yHat = np.sign(output)/2 +0.5 We just described what is known as a single-layer perceptron. This type of perceptron produces outputs that are linearly separable. This means that there exists some line that can be drawn between our two output sets. Note that this is only the case if there are two input dimensions. With three input dimensions, the data “live” in a 3D scatterplot, and it requires a plane to separate the classes. In more than three dimensions, a hyperplane is necessary. Single-layer perceptrons can solve simple problems like representing logic operators AND, OR, and NOT. However, these single-layer perceptrons are incapable of solving a more complex problem such as XOR because the outputs cannot be produced from a linear combination of inputs (the outputs are not linearly separable). Exercise 5: What is the difference between a single layer perceptron and an MCP neuron? Exercise 6: Explain how a perceptron functions. Which step contributes most to the “learning” process? Figure 9.2: A visual demonstrating the distinction between linearly and nonlinearly separable problems. The left image shows a linearly separable problem that can be solved with a single line. The right image shows a nonlinear problem that cannot be solved with a single line. One of the major shortcomings of the single-layer perceptron is its activation function. We already mentioned the activation function of the single-layered perceptron as being a step function: Figure 9.3: Graph of a step function that can only oscillate between 0 and 1. The function begins at 0 and then at some time theta directly rises to 1. The main fault of the step function, however, is that it cannot represent small changes in the weights to reduce error and approach the optimal solution. This is because the activation function is not differentiable. Therefore, if there is an error in the output, changes made to the weights are constant and are not dependent on the change in input. Now consider a multilayer perceptron with a differentiable nonlinear activation function. If the activation function is differentiable, then you can make gradual changes to the weights and bias so as not to overshoot the optimal solution. Consider an alternative activation function: Figure 9.4: Graph of a sigmoid function that gradually changes between 0 to 1 in a curved line. We call this the sigmoid activation function. While the step function has an output of either 0 or 1, the output of the sigmoid function is continuous between 0 and 1. There also exists some threshold for decision making in both functions. Another distinction between sigmoid and the step function is that sigmoid is a smooth curve that is differentiable everywhere. This allows us to be able to make slight adjustments to our weights. Thus, the process of tuning weights and bias is gradual and leads to better learning in these networks. Earlier we explained a single-layer perceptron as having a step function, which is just one of many possible activation functions. When our output is not linearly separable, which is the case in most real-world problems, we chain layers of neurons together and use multiple nonlinearities from the various units to solve the problem–these added layers are known as hidden layers . Each of these hidden layers–as well as the output layer–will have its own activation function, and will make a decision based on some input (neural feature). The output of this function is mapped between 0 and 1 where 0 means the feature is not present and 1 means it is present, given a differentiable activation function. Non-linearity is required as we are attempting to produce a non-linear decision boundary between two sets (see 9.4). Furthermore, if we only use linear activation functions, we can add any number of additional layers to our network and the final output is simply a linear combination of the initial input data. In other words, if we had no activation functions and we were to merely pass the weights from layer to layer, the output would be a linear combination of the inputs. Figure 9.5: Example of a multilayer network. (Glosser.ca, 2013) Exercise 7: Why is it that the activation function produces linear data? Why is linear data a problem with respect to real-world situations? In 1986, Hinton et al published “Learning representations by back-propagating errors.” This paper introduced two concepts that allow for these non-linear activation functions to learn more complicated features. The first being the addition of hidden layers, as mentioned earlier, to the perceptron. These are nodes representing neurons in the network between the input and output. It is these hidden layers explicitly that allow for multilayer perceptrons i.e. neural networks, to learn more complicated features (like XOR). The second of these concepts is backpropagation, a procedure to repeatedly adjust the weights to decrease the difference between the network output and the desired output. Backpropagation is performed by calculating the cost of an output neuron. One example of a cost function is Mean Squared Error, which allows us to calculate cost via:\\[ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_{i} - Yhat_{i})^2\\] In the cost function, \\(Y_{i}\\) is the output of our activation function and \\(\\hat{Y}_{i}\\) is our desired output. We take the output of our cost function and use it to make changes in our weights with the goal of minimizing cost for the next iteration through our network. Note that in order for backpropagation to be possible, our activation function must be differentiable between 0 and 1 e.g. the sigmoid function, but the step function is not. For a detailed explanation of how backpropagation works, check out this video. Exercise 8: Explain why backpropagation and hidden layers are necessary for the perceptron to optimize its learning capabilities. Exercise 9: Why is the sigmoid function a better alternative than the activation function for multilayered perceptrons? Exercise 10: Think back to real neurons. How does a multilayered perceptron compare to an actual neural network? What strengths does it have, and what weaknesses? Code exercise (continued): Below is the completed for loop following from the previous code snippet. Note the manner in which we updated the weights. # Calculate the error between predicted y and your expected Y1 error = (Y1 - yHat) # Compute delta weights. This step is where the # model starts to &#39;learn&#39; based on the difference # between expected output and the actual output. # Delta weight will be the change of weight. It is # based on input value and error size. deltaW = eta * np.matmul(X1.T, error) # Update weights weights = weights + deltaW # Store accuracy for the prediction along iterations accuracy[i] = len(error[error==0]) / 4 # Plotting plt.figure() plt.plot(accuracy) plt.xlabel(&#39;iterations&#39;) plt.ylabel(&#39;percent accuracy&#39;) 9.6 Summary Neural Networks have come quite far in the last half-century. What was initially thought to exist exclusively in the brain can now be replicated in an algorithm. It was not until the creation of the McCulloch-Pitts neuron, followed by the extension into the perceptron before people were convinced that a machine could learn. People initially believed that the perceptron is useless as they could not represent logic as simple as XOR with their single layer. It was not until Geoffery Hinton pioneered the creation of the multilayer perceptron that artificial neural networks were respected as a strong representation of how a computer can learn. Hinton and his collaborators are responsible for many of the significant leaps in programming computers to learn. The introduction of backpropagation and hidden layers to neural networks allowed for substantial progress to be made in the field of Artificial Intelligence. Neural networks are perhaps the most hyped topic in the tech world today. As we journey further into the 21st century, we are constantly bombarded with headlines and news feeds of self-driving cars, agents teaching themselves to play hide and seek, and the greatest chess engine the world has seen that taught itself to play in a few hours. There is no doubt that it is an exciting time to be a neuroscientist; we are at the forefront of considerable innovation and it all emerges from the material discussed in this chapter. Coding Challenge Following the code given in this chapter, try to make a model for an XOR gate. Does the accuracy change when you do more iterations? Explain your result. Hint: consider the term “linearly separable”. "],
["Ch9.html", "10 Glossary", " 10 Glossary Absolute Refractory Period: The point from the beginning of the action potential to the peak. In this time frame, it is not physiologically possible for the neuron to fire a second time. In this time period, the sodium channels are open and remain open until the peak of the graph. These channels can not immediately re-open, and due to this, it would not be possible for the membrane to depolarize a second time. Activation Function: Allows for a neuron to make a decision (produce an output) along some continuous interval to adjust weights to learn. Algorithm: An algorithm is a process to define why the model is appropriate and how the logical strategy will be carried out. Back Propagation: Correction signals that run backwards from the output units to the hidden units and then are summed according to the hidden-to-output weights. Bottom-up Processing: Bottom-up organization refers to the reverse process, collecting data and then organizing it to create a theory. Classifier: A type of supervised learning that learns from training data and makes predictions on test data. Specific types of classifiers include: Distance-based classifier Boundary-based classifier Coefficient of Variation: Standard deviation divided by the mean of a set of data. Computational Neuroscience: Computational neuroscience is an interdisciplinary field that applies the principles of mathematics, philosophy, and computer science to study the inner workings of the brain. Computational Theory: Computational Theory a characterization of the system’s goal. Conductance: Allows the flow of charge. Cost: Calculation in Backpropagation using the Mean Squared Error: \\(MSE = \\frac{1}{n}\\sum_{i=1}^{n} (Y_{i}-Yhat_{i})^2\\). Used to change weights with the goal of minimizing cost at each iteration. Cross-validation: A decoding scheme that repeatedly partitions the data set into a test set and the remaining data into a training set and makes predictions for every test set until predictions are made for every data point in the data set. Curse of dimensionality: As we move up to in dimensions and start calculating distances in hyperplanes, these operations become exponentially less efficient. Decoding: Field of neuroscience aimed at using action potential data in a single neuron or neural networks to identify the stimuli that caused the neural activity. Depolarization: This process of positive ions flowing into the cell. Driving Force: The pressure for an ion to move in or out of the cell. Emergent Phenomena: An emergent phenomenon is a case in which new mechanisms arise from the addition of a sufficient number of the same functional part. Equilibrium Potential: The membrane potential at which the flow of electric current from all types of ions into and out of the cell is balanced, so there is no net current and the membrane potential is not caused to change. Fano Factor: The fano factor is used to measure the spike variability in a spike train. It is calculated by the variance of the number of spikes divided by the mean number of spikes in a given time interval. Gating variable: The Fire Model is broken up into three separate conductance terms, each relating to a different ion channel called the m, h, and n variables. Hardware and Implementation: Hardware implementation is the physical machinery that realizes the algorithm. Hebbian Learning: One of the core levels of organization within the brain is the synapse. The synapse consists of a pre-synaptic cell, which sends a message to another neuron, or the post-synaptic cell. When many of these messages are sent between two cells, the connection between the two of them is strengthened. This is a theory of “synaptic plasticity” which can be applied through theoretical models within the field of neuroscience. Hidden Layers: Additional layers used when an output is not linearly separable (like XOR); these layers of neurons are chained together via multiple nonlinearities from the various units to solve the problem. Each of these hidden layers–as well as the output layer–will have its own activation function. Hyperpolarization: To decrease the membrane potential towards a more negative value through outward electrical current. Imaging techniques: There are multiple types of imaging techniques commonly employed by researchers to obtain data and recordings from participants. The techniques include: EEG MEG fMRI ECOG Interspike Interval: The time interval between every pair of spikes. Leak Current: Leak currents are the passive membranes that are dependent on the membrane potential to drive the electrical potentials of the permeable ions and concentration gradient. Linear discriminant analysis: Type of decision-based classifier algorithm that maximizes that distance between centroid means. Linear support vector machine (LSVM): type of decision-based classifier algorithm that creates a boundary that maximizes the distance between the hard examples in the training set (known as the support vectors); LSVM works well with high dimensional data. Linearly Separable: Different classes of outputs in space that can be separated with a single decision surface. McCulloch-Pitts (MCP) Neuron: Initial neural network model designed by McCulloch and Pitts that takes multiple inputs with associated weights to produce a single output. Membrane Potential: The potential difference across the cell membrane. Multivariate pattern analysis (MVPA): Method utilized for all the imaging techniques as a broad form of decoding that factors in the relationship between variables so they are not treated as independent variables. Negative Feedback: A process by which an initial change is opposed by a force caused by the initial change. Nernst Potential (Reversal Potential): The membrane potential at which the flow of a particular ion is in a dynamic equilibrium, meaning the outflow is precisely matched by the inflow of that ion. Neural Networks: Computing model comprised of basic processing elements strung together that take an input and give an appropriate output and can become increasingly layered to conquer more complex concepts and problems. Perceptron: An algorithm for transforming inputs to outputs with the corresponding weights, bias, and the activation function. Peri-Stimulus Time Histogram: Average time-dependent rate of action potentials (or spike rate) measured during a stimulus over a period of time. Poisson Process: Probabilistic production of events, such as spikes, at any point in time with equal probability per unit time. Positive Feedback: A process by which depolarization of the cell causes further depolarization. More generally, a positive feedback loop is a process that perpetuates itself. Rank measure: A type of decoding that ranks the probability for all labels and measures the distance between the predicted label and the top. Reconstructionism: Reconstructionism is similar to reductionism, except with the added step of reconstructing the reduced parts. Reductionism: Reductionism is breaking larger concepts or models down into smaller parts. Reinforcement Learning: Learning shaped through interactions with the environment through reward and punishment. Relative Refractory Period: The point after the absolute refractory period when a second stimulus, that is above a threshold, can elicit a second action potential without allowing the membrane to hyperpolarize back to its resting membrane potential. Representation: The representational scheme is the description of the functional elements that are used in the computation. Reverse Correlation: Process which implements the analysis of outputs to determine the inputs that the neuron will respond to with a spike. Sigmoid Activation Function: One type of non-linear activation function that determines the output, whose function is defined to be \\(f(x) = \\frac{1}{(1+e^-x)}\\) Sodium-Potassium Pump: Uses just below 10% of your body’s daily energy to pump three sodium ions out of the neuron for every two potassium ions pumped in, thus forming two respective concentration gradients. Spike Count Rate: The number of spikes per time interval. Spike Train: A sequence of recorded times at which a neuron fires an action potential. Spike Triggered Average: The average value of the stimulus during some time interval before a spike occurs. Step Function: One type of activation function that takes returns a binary output of 0 or 1. Supervised Learning: Learning situations where inputs and expected outputs are given information to predict future solutions. Top-down Processing: Top-down organization refers to the idea of designing a machine for an express predisposed class. Turing Machine: The Turing Machine is a theory created by Alan Turing involving an infinite strip of paper with binary cells which can be used to compute any questions theoretically. Unsupervised Learning: Learning that occurs in the absence of a teacher with expected outputs; a student simply looks at patterns and tries to maximize correlations or find a basic understanding or pattern. White Noise: A random variation where the value at each time point is independent of all other points and so can be employed in these instances to provide a receptive field without bias. "],
["Ch10.html", "11 References 11.1 Chapter 1: Preface 11.2 Chapter 2: Introduction to Python 11.3 Chapter 3: What is Computational Neuroscience? 11.4 Chapter 4: Passive Membrane Models 11.5 Chapter 5: Hodgkin and Huxley 11.6 Chapter 6: Firing Rates 11.7 Chapter 7: Reverse Correlation and Receptive Field Mapping 11.8 Chapter 8: Decoding 11.9 Chapter 9: Neural Networks", " 11 References *** Denotes references of particular interest. 11.1 Chapter 1: Preface 11.2 Chapter 2: Introduction to Python 11.3 Chapter 3: What is Computational Neuroscience? Anderson, B. (2014). Computational Neuroscience and Cognitive Modelling: A Student’s Introduction to Methods and Procedures: SAGE Publications. Hodges, A. (2009). Alan Turing and the Turing Test. Epstein, R., Roberts G., &amp; Beber, G. (Ed.) Parsing the Turing Test: Philosophical and Methodological issues in the Quest for the Thinking Computer. (pp. 13-22). Springer. Lytton, W. W. (2002). From Computer to Brain: Foundations of Computational Neuroscience: Springer. Markram, H. (2006). The Blue Brain Project. Nature Reviews Neuroscience, 7(2), 153-160. doi:10.1038/nrn1848 *** Marr, D. (1982). The Philosophy and the Approach. Vision. San Francisco: Freeman. O’Reilly, R., &amp; Munakata, Y. (2000). Computational Explorations in Cognitive Neuroscience Understanding the Mind by Simulating the Brain. MIT Press. P. Trappenberg, T. (2002). Fundamentals of Computational Neuroscience: Oxford University Press UK. *** Pessoa, L. (2017). Do Intelligent Robots Need Emotion? Trends in Cognitive Sciences, 21(11), 817-819. doi:https://doi.org/10.1016/j.tics.2017.06.010 Selfridge, O. G. (1955, March). Pattern recognition and modern computers. In Proceedings of the March 1-3, 1955, Western Joint Computer Conference (pp. 91-93). ACM. Studios, BBC, director. The Chinese Room Experiment - The Hunt for AI. YouTube, YouTube, 17 Sept. 2015, www.youtube.com/watch?v=D0MD4sRHj1M. 11.4 Chapter 4: Passive Membrane Models 11.5 Chapter 5: Hodgkin and Huxley Anderson, B. (2014). Computational Neuroscience and Cognitive Modelling: A Student’s Introduction to Methods and Procedures: SAGE Publications. Dayan, P. A., L. F. (2005). Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems (T. M. Press Ed.). Discovery. “Dancing Zombie Squid Explained.” YouTube, YouTube, 10 Aug. 2011, www.youtube.com/watch?v=JGPfSSUlReM. Lytton, W. W. (2002). From Computer to Brain: Foundations of Computational Neuroscience: Springer. Mallot, H. A. (2013). Computational Neuroscience (S. International Ed.). Switzerland. P. Trappenberg, T. (2002). Fundamentals of Computational Neuroscience: Oxford University Press UK. Sterratt, D. G., Bruce; Gillies, Andrew; Willshaw, David. (2011). Principles of Computational Modelling in Neuroscience (Cambridge University Press ed.). 11.6 Chapter 6: Firing Rates Background: Spike Trains as Point Processes. (n.d.). Retrieved October 10, 2019, from http://www.stat.cmu.edu/~kass/contrib.html#background. Jaeger, D., Jung, R., &amp; Springer. (2015). “Spike Train.” Encyclopedia of Computational Neuroscience: Springer. 11.7 Chapter 7: Reverse Correlation and Receptive Field Mapping Mallot, H. A. (2015). “Chapter 2 Receptive Fields and the Specificity of Neuronal Firing.” Computational Neuroscience: A First Course. Berlin: Springer. Dayan, P., &amp; Abbott, L. F. (2001). “1.3 What Makes a Neuron Fire?” Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems: MIT Press. Ringach, D., &amp; Shapley, R. (2004). Reverse correlation in neurophysiology. Cognitive Science, 28(2), 147–166. doi: 10.1207/s15516709cog2802_2 Schwartz, O., Pillow, J. W., Rust, N. C., &amp; Simoncelli, E. P. (2006). Spike-triggered neural characterization. Journal of Vision, 6(4), 13. doi: 10.1167/6.4.13 Rieke, F. (1999). Spikes: exploring the neural code. Cambridge, MA: MIT Press. Chichilnisky, E. J. “A Simple White Noise Analysis of Neuronal Light Responses.” Network: Computation in Neural Systems, vol. 12, no. 2, 2001, pp. 199–213., doi:10.1080/713663221. Gerstner, Wulfram. “8.1 Noise Input.” 8.1 Noise Input | Neuronal Dynamics Online Book, neuronaldynamics.epfl.ch/online/Ch8.S1.html. 11.8 Chapter 8: Decoding Glover, G. H. (2011). Overview of Functional Magnetic Resonance Imaging. Neurosurgery Clinics of North America, 22(2), 133–139. doi: 10.1016/j.nec.2010.11.001 Grootswagers, T., Wardle, S. G., &amp; Carlson, T. A. (2017). Decoding Dynamic Brain Patterns from Evoked Responses: A Tutorial on Multivariate Pattern Analysis Applied to Time Series Neuroimaging Data. Journal of Cognitive Neuroscience, 29(4), 677–697. doi: 10.1162/jocn_a_01068 Haxby, J. V. (2012). Multivariate pattern analysis of fMRI: The early beginnings. NeuroImage, 62(2), 852–855. doi: 10.1016/j.neuroimage.2012.03.016 Lecture 2: k-nearest neighbors. (n.d.). Retrieved from http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html. Kriegeskorte, N., &amp; Kreiman, G. (2012). Visual population codes: toward a common multivariate framework for cell recording and functional imaging. Cambridge, MA: MIT Press. Singh, S. (2014). Magnetoencephalography: Basic principles. Annals of Indian Academy of Neurology, 17(5), 107. doi: 10.4103/0972-2327.128676 11.9 Chapter 9: Neural Networks 3Blue1Brown. “Backpropagation Calculus | Deep Learning, Chapter 4.” YouTube,YouTube, Nov. 2017. Anderson, B. (2014). Computational Neuroscience and Cognitive Modelling: A Student’s Introduction to Methods and Procedures: SAGE Publications. Baker, Bowen. “Emergent Tool Use from Multi-Agent Interaction.” OpenAI, OpenAI, 29 Oct. 2019, openai.com/blog/emergent-tool-use/. Glosser.ca. (2013). Colored neural network. Wikimedia. Kang, N. (2017). Introducing Deep Learning and Neural Networks — Deep Learning for Rookies. Towards Data Science. Kang, N. (2017). Multi-Layer Neural Networks with Sigmoid Function— Deep Learning for Rookies. Towards Data Science. *** Lettvin, J. Y., Maturana, H. R., McCulloch, W. S., &amp; Pitts, W. H. (1959). What the Frog’s Eye Tells the Frog’s Brain. Proceedings of the IRE, 47(11), 1940-1951. doi:10.1109/JRPROC.1959.287207 Lytton, W. W. (2002). From Computer to Brain: Foundations of Computational Neuroscience: Springer. Mallot, H. A. (2013). Computational Neuroscience (S. International Ed.). Switzerland. Murphy, K. P. (2012). Introduction Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series) (1st ed.). P. Trappenberg, T. (2002). Fundamentals of Computational Neuroscience: Oxford University Press UK. Silver, David, et al. “AlphaZero: Shedding New Light on the Grand Games of Chess, Shogi and Go.” Deepmind, Dec. 2018, deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go. Tesla. “Full Self-Driving.” YouTube,YouTube,www.youtube.com/watch?v=tlThdr3O5Qo. "],
["Ch11.html", "12 Answers to Exercises 12.1 Chapter 1: Introduction to Python 12.2 Chapter 2: Introduction to Computational Neuroscience 12.3 Chapter 3: Passive Membrane Models 12.4 Chapter 4: Hodgkin and Huxley 12.5 Chapter 5: Firing Rates 12.6 Chapter 6: Reverse Correlation and Receptive Field Mapping 12.7 Chapter 7: Decoding 12.8 Chapter 8: Neural Networks", " 12 Answers to Exercises 12.1 Chapter 1: Introduction to Python Conceptual Questions 1. Python reads the code provided the same way that we read, left to right, top to bottom! In Python, brackets are used to make lists. Parentheses are used to make tuples. However, when indexing for any of these collections, only brackets are used. Parentheses are also used when providing inputs for functions for example; when using NumPy’s function for the mean, you would use parentheses in “np.mean(XXX). It should be noted that all shells of the parentheses should be accounted for as not doing so can result in painful syntax errors. A tuple is defined as a sequence of items that cannot be changed, also characterized as immutable. A list is defined as a sequence of items that can be changed, also known as mutable. When writing tuples use a set of parentheses, and for lists use brackets. In Python, indentations are necessary as they indicate where the statement belongs to in terms of blocks of code. In Python, indentations indicate specifically where in the block of code a statement belongs. Additionally, the amount of indentation is important because if there is extra space or missing space within a block of Python code, it likely will cause a syntax error or change your desired outcome. In Python, the four most common types of data that Python supports with variables are “int”, “float”, “bool”, and “str”. Int can be either a positive or negative integer also known as a whole number. Floats, also known as floating point numbers, are positive or negative numbers that have a decimal point. These can be used in scientific notation. Bool is short for Boolean, which is the variable with two possible values, True and False. When writing Booleans, the first letter of the variable must be capitalized (True/False) so that Python can recognize the key words. Python confirms this by displaying the syntax coloring. Finally, str means string, and is used when you want to write text into the Python code. When you want to use a string, you must contain the text wanted within quotation marks so that Python does not read the text as a command. Python Exercises Question 1: varOne = 20 varTwo = 5 # Part A addVar = varOne + varTwo print(addVar) # Part B divVar = varOne / varTwo print(divVar) # Part C multVar = addVar * divVar print(multVar) Question 2: L1 = [&#39;berries&#39;, &#39;cake&#39;, &#39;chips&#39;, &#39;candy&#39;, &#39;apple&#39;] print(L1) print(L1[2:4]) L2 = [&#39;soccer&#39;, &#39;baseball&#39;, &#39;golf&#39;] print(L2) print(sorted(L2)) Question 3: import numpy as np vector1 = np.arange(5, 15, 2) print(vector1 ** 2) Question 4: import numpy as np matrix1 = np.zeros((3, 6)) print(matrix1) matrix2 = np.array([[&#39;Chocolate&#39;,&#39;Strawberry&#39;,&#39;Vanilla&#39;], [&#39;RootBeer&#39;,&#39;Orange&#39;,&#39;Pepsi&#39;)]]) print(matrix2) Question 5: for x in range(58, 71, 1): ifx%2 ==0: print(&#39;The number &#39; + str(x) + &#39; is an even number.&#39;) else: print(&#39;The number &#39; + str(x) + &#39; is an odd number.&#39;) 12.2 Chapter 2: Introduction to Computational Neuroscience No suggested answer, just enjoy learning about the automata. It turns out that Conway’s Game of Life is Turing-complete, which means that anything that can be computed can be computed with a GoL! (Might take a while, though!) The methods differed (on an implementation level), but the mental math and process of addition is the same. You took the input (the two numbers), processed them through an algorithm (symbolized by the addition symbol), and your output, hopefully, was 10. TBD TBD TBD TBD 12.3 Chapter 3: Passive Membrane Models 12.3.1 Conceptual Questions The neuron begins at resting potential. In this state, the membrane potential is about -70 mV, all voltage gated channels (VG) closed, and potassium may move through leak channels. Current will eventually enter through the ligand-gated channels raising the membrane potential to around -50 mV. At this voltage, a threshold is met and voltage-gated Na+ channels open. Na+ ions flood into the cell and further depolarize it in a positive feedback loop. Eventually voltage-gated Na+ channels will be inactivated, marking the absolute refractory period. Voltage-gated K+ channels will open (usually around 40 mV), and K+ rushes out of the cell. Following this period, the relative refractory period occurs in which voltage-gated Na+ channels are no longer inactivated, but the cell is hyperpolarized, making it more difficult, but still possible, for another action potential to occur. The resting potential of a neuron is also known as an ionic steady state because the ion movement is steadily maintaining a resting membrane potential of around -70 mV. Ions naturally want to even out a concentration gradient to achieve equilibrium. When these ions are forced to maintain an unequal gradient there is a resulting potential energy. On the other hand, ions are attracted to opposite charges (positive and negative attract). This potential is how much energy is required to oppose net diffusion for an ion and is known as the Nernst potential. Each of the major ions (Na+, K+, Cl-, Ca2+) have a Nernst potential, and a weighted average of these Nernst potentials. The weights are provided by the relative permeability of the various ions across the membrane. These permeabilities are related to the density of ion channels in the membrane, as well as the extent to which the channels will allow ions to flow. The reversal potential for a specific ion can be calculated with the Nernst equation. However, a more realistic idea of the reversal potential for the whole membrane would incorporate more than one ion. The way to calculate this information is with the Goldman-Hodgkin-Katz (GHK) equation. The GHK equation can only be calculated when more than one of the transmembrane ion channels is open. Different ways that ions can cross membranes include: Voltage-gated ion channels: when a voltage threshold is achieved, the channel will open for a specific amount of time allowing a particular ion to flow down its concentration gradient. Ligand-gated ion channels: Ligand-gated channels open when a particular hormone or neurotransmitter binds to the postsynaptic cell. After binding, specific ions can flow down their concentration gradient and into the cell. Mechanically-Gated Channels: Are opened by mechanical movement such as pressure on someone’s skin and allow ions to flow in. Leak Channels: Leak channels are quite self-explanatory. In the cell, there are channels in which potassium and occasionally chloride can very slowly leak out and diffuse out of the cell. Pumps: There are also pumps that can move particular ions against their concentration gradient. A great example of this is the sodium potassium pump which exchanges three Na+ ions out for 2 K+ ions in with energy from ATP. The correct matches are: Water:: Ions Water naturally wants to fill space just like ions naturally wanting to balance concentration gradients. Water will build potential energy when blocked from an area that it wants to flow to. Dam::Voltage-gated ion channels A dam in a river is just like a closed voltage gated channel. The water is higher on one side than the other so potential energy is built up and then transferred into kinetic energy when the dam opens. This is just like sodium ions wanting to flow into the cell when a channel opens. Water stream::Ion pump Additionally, forcing water against gravity involves externally applied energy. In cells, ATP is used to power pumps that can move ions to places they don’t want to go just like a generator powering a water jet. The leaky integrate and fire model considers the membrane to be a resistor-capacitor (RC) circuit. It is a resistor because ions cannot flow freely across the membrane, but instead need to flow through selective channels. It is a capacitor because the small size of the membrane makes for effective separation of charge (negative ions on the inside and positive on the outside). If this circuit is provided with an external current, the change in potential across the membrane is a product of both resistive and capacitive currents that flow. However, the model does not fire on its own. As an experimenter, we assign a threshold and state that the neuron has fired once that threshold has been exceeded. Some of the ways in which the leaky integrate and fire model is unrealistic include: It does not model individual ion conductances, but rather places them into one leak term. It does not fire on its own. We have to code the action potentials in by hand. It does not include any spatial terms for the action potential propagating down the axon. TBD TBD 12.3.2 Coding Questions 1a. # Step 1: Import libraries from numpy import log # Step 2: Define general function def Eion(z, o, i): return z * log(o/i) # Step 3: Use function to print the Nernst potential of each ion # Step 3.1: Na+ ion print(Eion(1, 2, 1)) # Step 3.2: K+ ion print(Eion(1, 1, 2)) # Step 3.3: Cl- ion print(Eion(-1, 2, 1)) # Answer: Na+ is positive, K+ and Cl- are negative 1b. # Step 1: Edit general function to use physiological values def Eion(z, o, i): return 26.5/z * log(o/i) # Step 2: Use function to print the Nernst potential of each ion # Step 2.1: Na+ ion print(Eion(1, 145, 15)) # Step 2.2: K+ ion print(Eion(1, 4, 150)) # Step 2.3: Cl- ion print(Eion(-1, 110, 11)) # Answers: # Na+: 60.1 mV # K+: -96 mV # Cl-: -61 mV 2a # Step 1: Import the necessary Python libraries from numpy import log # Step 2: Set up the general function def Vrest(Nao, Nai, Ko, Ki, pCl, Cli, Clo): return 26.5 * log((0.05*Nao + 1*Ko + pCl*Cli) / (0.05*Nai + 1*Ki + pCl*Clo)) # Step 3: Use the function along with the provided values print(Vrest(145, 15, 4, 150, 0.45, 10, 110)) #Answer: -67 mV 2b # Change the values for pCl and [out] and [in] for Cl- print(Vrest(145, 15, 4, 150, 0.1, 110, 10)) # Answer: Vrest=-50.9 # This resting potential is less negative, making it more likely to fire an action potential. 12.4 Chapter 4: Hodgkin and Huxley 12.4.1 Conceptual Questions: TBD An example of negative feedback is: In the rising phase of the action potential, there is less driving force on Na+ as Vm approaches the Nernst potential for Na+. An example of positive feedback is: An initial depolarization of the membrane causing voltage-gated Na+ channels to open. This allows for more Na+ to enter, which further depolarizes the cell. The main difference between the leaky integrate and fire model, and the Hodgkin and Huxley model is the inclusion of the Na+ and K+ channels instead of just using the leak channels. Including the Na+ and K+ voltage gated channels allows the H-H model to spike on its own. In the Integrate and Fire model, one must include artificial spikes to see the relationship between the applied current, the membrane threshold and the conductance of the leak channels. TBD TBD 12.4.2 Coding Questions: Problem 1, part 1: tStimStart = 100 tStimEnd = 400 tFinal = 500 dt = 0.1 Ie = 100 RestingPotential = -65 HHmodel(Ie, dt, tFinal, tStimStart, tStimEnd, RestingPotential) Problem 1, part 2: Set \\(I_e\\) to 250. The firing rate increases. Problem 2, part 1: # Note: as long as the range includes 13, this will work Ie = np.arange(20) HHmodel_threshold(Ie) Problem 2, part 2: Ie = [12,13] RestingPotential = -65 HHmodel_compare(Ie,RestingPotential) Problem 2, part 3: restingPotential = -60 Problem 3, part 1: if timeVec[v] &gt;= 300: beta_h = 0 Problem 3, part 2: if timeVec[v] &gt; 600: alpha_m = 0 Problem 3, part 3: If TTX was indeed a cure, then there should be action potentials occurring in that range between 600 and 800 ms. 12.5 Chapter 5: Firing Rates 12.5.1 Conceptual Questions The spike count rate is defined as the spike count during an interval of time, divided by the length of time, average over time. While this is an easy method to apply mathematically, it is not a continuous method. This means that this method does not reflect that the rates change over time, instead it assumes that rate stays the same. The spike density rate is defined as the number of spikes observed during a time interval divided by the number of trials that were run, then multiplied by one divided by the length of the time interval, average over several runs. However, this requires multiple trial runs for usable data. As a result, it is not a good model for real world situations, as events do not happen repeatedly. The spike density rate is defined as the number of spikes observed during a time interval divided by the number of neurons on which trials were run, then multiplied by one divided by the length of the time interval, average over several neurons. This method is continuous, and it is all done in one trial, instead of several trial runs. However, depending on the electrode to work simultaneously makes this method hard to execute. Additionally, the neurons need to all have the same basic computation. TBD 12.5.2 Coding Questions Problem 1, parts a and b. # Import the necessary libraries import matplotlib.pyplot as plt import numpy as np # Initialize data structures # Hint: your simulation runs for 2000 ms timeVec = np.arange(2000) # Hint: you may express your desired rate as a nSpikes / 1000 ms probability probability = 50/1000 # Hint: you want the default value to be zero spikes = np.zeros(len(timeVec)) # Loop through each time point - fill in missing code for i in range(len(timeVec)): if np.random.rand() &lt; probability: # fill in this key line spikes[i] = 1 # Compute the spike count rate here spikeCountRate = np.sum(spikes) / 2 # Print the spike count rate print(&#39;The firing rate was: {} Hz&#39;.format(spikeCountRate)) # Create a figure of the spike train plt.figure() plt.plot(timeVec, spikes) plt.title(&#39;Spikes versus Time&#39;) plt.xlabel(&#39;Time (ms)&#39;) plt.ylabel(&#39;Spikes&#39;) Problem 1, part c. # Import necessary libraries import matplotlib.pyplot as plt import numpy as np # Find locations of spikes in vector spikeLocs, = np.where(spikes == 1) # Pre-allocate space for ISIs ISI = np.zeros(len(spikeLocs)-1) # Loop through all spikes for i in range(len(ISI)): ISI[i] = spikeLocs[i+1]-spikeLocs[i] # Create a plot of the results plt.figure() plt.hist(ISI) plt.ylabel(&#39;Counts&#39;) plt.xlabel(&#39;ISI in ms&#39;) Problem 2, part a. # Import necessary libraries import numpy as np import matplotlib.pyplot as plt #fill in the time vector and the spike frequency value of 50 Hz timeVec = np.arange(2000) p1 = 50/1000 #Allocate space for the 40 trials x 2000 ms array allTrials = np.zeros((40, 2000)) #Create a Poisson spike generator, that loops 40 times for all 40 trials for i in range(40): # For each trial, use an inner loop to represent all 2000 time points for v in range(len(timeVec)): if np.random.rand() &lt; p1: allTrials[i, v] = 1 # Create the raster plot for j in range(40): # How many trials are we running? spikes, = np.nonzero(allTrials[j,:])#Fill in Spikes to represent every spike found in the allTrials matrix. Index the jth trial only. spikeTimes = timeVec[spikes] theseSpikes = np.ones(len(spikes))*j+1 plt.scatter(spikeTimes, theseSpikes, s=2, c=&#39;k&#39;) #Fill in the labels of the x, y axis plt.title(&#39;Poisson Model Firing Rates for 40 Trials&#39;) plt.xlabel(&#39;Time (ms)&#39;) plt.ylabel(&#39;Trial number&#39;) Problem 2, part b fano = np.var(allTrials) / np.mean(allTrials) print(fano) 12.6 Chapter 6: Reverse Correlation and Receptive Field Mapping 12.6.1 Conceptual Questions A white noise stimulus is first generated to record the neuron’s response to it. This random selection of stimuli is important in obtaining an independent assessment of the neuron’s preference. As different white noise stimuli are presented, the action potentials that the neuron fires are being recorded. A time window is then chosen to observe each time there is a spike. By creating a window of time, we can examine the response of the neuron to the stimulus over a particular time and detect the preferred time window for the neuron in which it will respond to the stimulus. The stimulus presented each time before a spike at their respective time windows is finally stored in an array and averaged over all the time steps to obtain the spike-triggered average. Point A has a higher level of resulting convolution because the stimulus and the STA (acting as the signal and kernel respectively), are aligned. This means that the stimulus has a lot of similarity with the preferred feature of the neuron at the given point of time, allowing the neuron to have a high firing rate. Point B, on the other hand, has very minimal neuronal firing due to the dissimilarity between the stimulus and the preferred feature. Possible examples of a white noise stimulus in different sensory systems: Auditory system: playing audio white noise that includes random amplitudes of a wide range of audible frequencies to determine the preferred frequency of the neuron. Visual system: (a) An array of pixels in which the gray level of each pixel is randomly and independently chosen. (b) Choosing a random brightness using a flashlight with a broad spectrum of degrees of brightness in random sequences to determine the neuron’s preferred light intensity. In reverse correlation, using Gaussian white noise as the stimulus gives a distribution of zero mean and constant variance of stimulus intensity over the time step given. With the different strengths of stimuli overlapping with each other, the adaptation effects are minimized as it is modeled to be constant during the white noise stimulation. A linear process only provides information on the degree of similarity between the stimulus and the STA. Firstly, the firing rates can take negative values from the linear approximation. Secondly, the firing rates can increase indefinitely as the input of stimulus intensity increases due to the continuity feature of the linear model. Thus, the non-linearity function is needed to eliminate these negative values and categorizing firing rates into super-threshold or sub-threshold through rectification because biologically, neurons will saturate as they have a maximum firing rate. 12.6.2 Coding Questions 12.7 Chapter 7: Decoding 12.8 Chapter 8: Neural Networks "]
]
